// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: yarn_service_protos.proto

#ifndef PROTOBUF_yarn_5fservice_5fprotos_2eproto__INCLUDED
#define PROTOBUF_yarn_5fservice_5fprotos_2eproto__INCLUDED

#include <string>

#include <google/protobuf/stubs/common.h>

#if GOOGLE_PROTOBUF_VERSION < 2005000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please update
#error your headers.
#endif
#if 2005000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/unknown_field_set.h>
#include "Security.pb.h"
#include "yarn_protos.pb.h"
// @@protoc_insertion_point(includes)

namespace hadoop {
namespace yarn {

// Internal implementation detail -- do not call these.
void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

class RegisterApplicationMasterRequestProto;
class RegisterApplicationMasterResponseProto;
class FinishApplicationMasterRequestProto;
class FinishApplicationMasterResponseProto;
class AllocateRequestProto;
class NMTokenProto;
class AllocateResponseProto;
class GetNewApplicationRequestProto;
class GetNewApplicationResponseProto;
class GetApplicationReportRequestProto;
class GetApplicationReportResponseProto;
class SubmitApplicationRequestProto;
class SubmitApplicationResponseProto;
class KillApplicationRequestProto;
class KillApplicationResponseProto;
class GetClusterMetricsRequestProto;
class GetClusterMetricsResponseProto;
class GetApplicationsRequestProto;
class GetApplicationsResponseProto;
class GetClusterNodesRequestProto;
class GetClusterNodesResponseProto;
class GetQueueInfoRequestProto;
class GetQueueInfoResponseProto;
class GetQueueUserAclsInfoRequestProto;
class GetQueueUserAclsInfoResponseProto;
class StartContainerRequestProto;
class StartContainerResponseProto;
class StopContainerRequestProto;
class StopContainerResponseProto;
class GetContainerStatusRequestProto;
class GetContainerStatusResponseProto;
class StartContainersRequestProto;
class ContainerExceptionMapProto;
class StartContainersResponseProto;
class StopContainersRequestProto;
class StopContainersResponseProto;
class GetContainerStatusesRequestProto;
class GetContainerStatusesResponseProto;

// ===================================================================

class RegisterApplicationMasterRequestProto : public ::google::protobuf::Message {
 public:
  RegisterApplicationMasterRequestProto();
  virtual ~RegisterApplicationMasterRequestProto();

  RegisterApplicationMasterRequestProto(const RegisterApplicationMasterRequestProto& from);

  inline RegisterApplicationMasterRequestProto& operator=(const RegisterApplicationMasterRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const RegisterApplicationMasterRequestProto& default_instance();

  void Swap(RegisterApplicationMasterRequestProto* other);

  // implements Message ----------------------------------------------

  RegisterApplicationMasterRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const RegisterApplicationMasterRequestProto& from);
  void MergeFrom(const RegisterApplicationMasterRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string host = 1;
  inline bool has_host() const;
  inline void clear_host();
  static const int kHostFieldNumber = 1;
  inline const ::std::string& host() const;
  inline void set_host(const ::std::string& value);
  inline void set_host(const char* value);
  inline void set_host(const char* value, size_t size);
  inline ::std::string* mutable_host();
  inline ::std::string* release_host();
  inline void set_allocated_host(::std::string* host);

  // optional int32 rpc_port = 2;
  inline bool has_rpc_port() const;
  inline void clear_rpc_port();
  static const int kRpcPortFieldNumber = 2;
  inline ::google::protobuf::int32 rpc_port() const;
  inline void set_rpc_port(::google::protobuf::int32 value);

  // optional string tracking_url = 3;
  inline bool has_tracking_url() const;
  inline void clear_tracking_url();
  static const int kTrackingUrlFieldNumber = 3;
  inline const ::std::string& tracking_url() const;
  inline void set_tracking_url(const ::std::string& value);
  inline void set_tracking_url(const char* value);
  inline void set_tracking_url(const char* value, size_t size);
  inline ::std::string* mutable_tracking_url();
  inline ::std::string* release_tracking_url();
  inline void set_allocated_tracking_url(::std::string* tracking_url);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.RegisterApplicationMasterRequestProto)
 private:
  inline void set_has_host();
  inline void clear_has_host();
  inline void set_has_rpc_port();
  inline void clear_has_rpc_port();
  inline void set_has_tracking_url();
  inline void clear_has_tracking_url();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::std::string* host_;
  ::std::string* tracking_url_;
  ::google::protobuf::int32 rpc_port_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(3 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static RegisterApplicationMasterRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class RegisterApplicationMasterResponseProto : public ::google::protobuf::Message {
 public:
  RegisterApplicationMasterResponseProto();
  virtual ~RegisterApplicationMasterResponseProto();

  RegisterApplicationMasterResponseProto(const RegisterApplicationMasterResponseProto& from);

  inline RegisterApplicationMasterResponseProto& operator=(const RegisterApplicationMasterResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const RegisterApplicationMasterResponseProto& default_instance();

  void Swap(RegisterApplicationMasterResponseProto* other);

  // implements Message ----------------------------------------------

  RegisterApplicationMasterResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const RegisterApplicationMasterResponseProto& from);
  void MergeFrom(const RegisterApplicationMasterResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ResourceProto maximumCapability = 1;
  inline bool has_maximumcapability() const;
  inline void clear_maximumcapability();
  static const int kMaximumCapabilityFieldNumber = 1;
  inline const ::hadoop::yarn::ResourceProto& maximumcapability() const;
  inline ::hadoop::yarn::ResourceProto* mutable_maximumcapability();
  inline ::hadoop::yarn::ResourceProto* release_maximumcapability();
  inline void set_allocated_maximumcapability(::hadoop::yarn::ResourceProto* maximumcapability);

  // optional bytes client_to_am_token_master_key = 2;
  inline bool has_client_to_am_token_master_key() const;
  inline void clear_client_to_am_token_master_key();
  static const int kClientToAmTokenMasterKeyFieldNumber = 2;
  inline const ::std::string& client_to_am_token_master_key() const;
  inline void set_client_to_am_token_master_key(const ::std::string& value);
  inline void set_client_to_am_token_master_key(const char* value);
  inline void set_client_to_am_token_master_key(const void* value, size_t size);
  inline ::std::string* mutable_client_to_am_token_master_key();
  inline ::std::string* release_client_to_am_token_master_key();
  inline void set_allocated_client_to_am_token_master_key(::std::string* client_to_am_token_master_key);

  // repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;
  inline int application_acls_size() const;
  inline void clear_application_acls();
  static const int kApplicationACLsFieldNumber = 3;
  inline const ::hadoop::yarn::ApplicationACLMapProto& application_acls(int index) const;
  inline ::hadoop::yarn::ApplicationACLMapProto* mutable_application_acls(int index);
  inline ::hadoop::yarn::ApplicationACLMapProto* add_application_acls();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationACLMapProto >&
      application_acls() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationACLMapProto >*
      mutable_application_acls();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.RegisterApplicationMasterResponseProto)
 private:
  inline void set_has_maximumcapability();
  inline void clear_has_maximumcapability();
  inline void set_has_client_to_am_token_master_key();
  inline void clear_has_client_to_am_token_master_key();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ResourceProto* maximumcapability_;
  ::std::string* client_to_am_token_master_key_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationACLMapProto > application_acls_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(3 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static RegisterApplicationMasterResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class FinishApplicationMasterRequestProto : public ::google::protobuf::Message {
 public:
  FinishApplicationMasterRequestProto();
  virtual ~FinishApplicationMasterRequestProto();

  FinishApplicationMasterRequestProto(const FinishApplicationMasterRequestProto& from);

  inline FinishApplicationMasterRequestProto& operator=(const FinishApplicationMasterRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const FinishApplicationMasterRequestProto& default_instance();

  void Swap(FinishApplicationMasterRequestProto* other);

  // implements Message ----------------------------------------------

  FinishApplicationMasterRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const FinishApplicationMasterRequestProto& from);
  void MergeFrom(const FinishApplicationMasterRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string diagnostics = 1;
  inline bool has_diagnostics() const;
  inline void clear_diagnostics();
  static const int kDiagnosticsFieldNumber = 1;
  inline const ::std::string& diagnostics() const;
  inline void set_diagnostics(const ::std::string& value);
  inline void set_diagnostics(const char* value);
  inline void set_diagnostics(const char* value, size_t size);
  inline ::std::string* mutable_diagnostics();
  inline ::std::string* release_diagnostics();
  inline void set_allocated_diagnostics(::std::string* diagnostics);

  // optional string tracking_url = 2;
  inline bool has_tracking_url() const;
  inline void clear_tracking_url();
  static const int kTrackingUrlFieldNumber = 2;
  inline const ::std::string& tracking_url() const;
  inline void set_tracking_url(const ::std::string& value);
  inline void set_tracking_url(const char* value);
  inline void set_tracking_url(const char* value, size_t size);
  inline ::std::string* mutable_tracking_url();
  inline ::std::string* release_tracking_url();
  inline void set_allocated_tracking_url(::std::string* tracking_url);

  // optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 3;
  inline bool has_final_application_status() const;
  inline void clear_final_application_status();
  static const int kFinalApplicationStatusFieldNumber = 3;
  inline ::hadoop::yarn::FinalApplicationStatusProto final_application_status() const;
  inline void set_final_application_status(::hadoop::yarn::FinalApplicationStatusProto value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.FinishApplicationMasterRequestProto)
 private:
  inline void set_has_diagnostics();
  inline void clear_has_diagnostics();
  inline void set_has_tracking_url();
  inline void clear_has_tracking_url();
  inline void set_has_final_application_status();
  inline void clear_has_final_application_status();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::std::string* diagnostics_;
  ::std::string* tracking_url_;
  int final_application_status_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(3 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static FinishApplicationMasterRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class FinishApplicationMasterResponseProto : public ::google::protobuf::Message {
 public:
  FinishApplicationMasterResponseProto();
  virtual ~FinishApplicationMasterResponseProto();

  FinishApplicationMasterResponseProto(const FinishApplicationMasterResponseProto& from);

  inline FinishApplicationMasterResponseProto& operator=(const FinishApplicationMasterResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const FinishApplicationMasterResponseProto& default_instance();

  void Swap(FinishApplicationMasterResponseProto* other);

  // implements Message ----------------------------------------------

  FinishApplicationMasterResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const FinishApplicationMasterResponseProto& from);
  void MergeFrom(const FinishApplicationMasterResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional bool isUnregistered = 1 [default = false];
  inline bool has_isunregistered() const;
  inline void clear_isunregistered();
  static const int kIsUnregisteredFieldNumber = 1;
  inline bool isunregistered() const;
  inline void set_isunregistered(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.FinishApplicationMasterResponseProto)
 private:
  inline void set_has_isunregistered();
  inline void clear_has_isunregistered();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  bool isunregistered_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static FinishApplicationMasterResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class AllocateRequestProto : public ::google::protobuf::Message {
 public:
  AllocateRequestProto();
  virtual ~AllocateRequestProto();

  AllocateRequestProto(const AllocateRequestProto& from);

  inline AllocateRequestProto& operator=(const AllocateRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const AllocateRequestProto& default_instance();

  void Swap(AllocateRequestProto* other);

  // implements Message ----------------------------------------------

  AllocateRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const AllocateRequestProto& from);
  void MergeFrom(const AllocateRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.ResourceRequestProto ask = 1;
  inline int ask_size() const;
  inline void clear_ask();
  static const int kAskFieldNumber = 1;
  inline const ::hadoop::yarn::ResourceRequestProto& ask(int index) const;
  inline ::hadoop::yarn::ResourceRequestProto* mutable_ask(int index);
  inline ::hadoop::yarn::ResourceRequestProto* add_ask();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ResourceRequestProto >&
      ask() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ResourceRequestProto >*
      mutable_ask();

  // repeated .hadoop.yarn.ContainerIdProto release = 2;
  inline int release_size() const;
  inline void clear_release();
  static const int kReleaseFieldNumber = 2;
  inline const ::hadoop::yarn::ContainerIdProto& release(int index) const;
  inline ::hadoop::yarn::ContainerIdProto* mutable_release(int index);
  inline ::hadoop::yarn::ContainerIdProto* add_release();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >&
      release() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >*
      mutable_release();

  // optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;
  inline bool has_blacklist_request() const;
  inline void clear_blacklist_request();
  static const int kBlacklistRequestFieldNumber = 3;
  inline const ::hadoop::yarn::ResourceBlacklistRequestProto& blacklist_request() const;
  inline ::hadoop::yarn::ResourceBlacklistRequestProto* mutable_blacklist_request();
  inline ::hadoop::yarn::ResourceBlacklistRequestProto* release_blacklist_request();
  inline void set_allocated_blacklist_request(::hadoop::yarn::ResourceBlacklistRequestProto* blacklist_request);

  // optional int32 response_id = 4;
  inline bool has_response_id() const;
  inline void clear_response_id();
  static const int kResponseIdFieldNumber = 4;
  inline ::google::protobuf::int32 response_id() const;
  inline void set_response_id(::google::protobuf::int32 value);

  // optional float progress = 5;
  inline bool has_progress() const;
  inline void clear_progress();
  static const int kProgressFieldNumber = 5;
  inline float progress() const;
  inline void set_progress(float value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.AllocateRequestProto)
 private:
  inline void set_has_blacklist_request();
  inline void clear_has_blacklist_request();
  inline void set_has_response_id();
  inline void clear_has_response_id();
  inline void set_has_progress();
  inline void clear_has_progress();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ResourceRequestProto > ask_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto > release_;
  ::hadoop::yarn::ResourceBlacklistRequestProto* blacklist_request_;
  ::google::protobuf::int32 response_id_;
  float progress_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(5 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static AllocateRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class NMTokenProto : public ::google::protobuf::Message {
 public:
  NMTokenProto();
  virtual ~NMTokenProto();

  NMTokenProto(const NMTokenProto& from);

  inline NMTokenProto& operator=(const NMTokenProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const NMTokenProto& default_instance();

  void Swap(NMTokenProto* other);

  // implements Message ----------------------------------------------

  NMTokenProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const NMTokenProto& from);
  void MergeFrom(const NMTokenProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.NodeIdProto nodeId = 1;
  inline bool has_nodeid() const;
  inline void clear_nodeid();
  static const int kNodeIdFieldNumber = 1;
  inline const ::hadoop::yarn::NodeIdProto& nodeid() const;
  inline ::hadoop::yarn::NodeIdProto* mutable_nodeid();
  inline ::hadoop::yarn::NodeIdProto* release_nodeid();
  inline void set_allocated_nodeid(::hadoop::yarn::NodeIdProto* nodeid);

  // optional .hadoop.common.TokenProto token = 2;
  inline bool has_token() const;
  inline void clear_token();
  static const int kTokenFieldNumber = 2;
  inline const ::hadoop::common::TokenProto& token() const;
  inline ::hadoop::common::TokenProto* mutable_token();
  inline ::hadoop::common::TokenProto* release_token();
  inline void set_allocated_token(::hadoop::common::TokenProto* token);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.NMTokenProto)
 private:
  inline void set_has_nodeid();
  inline void clear_has_nodeid();
  inline void set_has_token();
  inline void clear_has_token();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::NodeIdProto* nodeid_;
  ::hadoop::common::TokenProto* token_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static NMTokenProto* default_instance_;
};
// -------------------------------------------------------------------

class AllocateResponseProto : public ::google::protobuf::Message {
 public:
  AllocateResponseProto();
  virtual ~AllocateResponseProto();

  AllocateResponseProto(const AllocateResponseProto& from);

  inline AllocateResponseProto& operator=(const AllocateResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const AllocateResponseProto& default_instance();

  void Swap(AllocateResponseProto* other);

  // implements Message ----------------------------------------------

  AllocateResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const AllocateResponseProto& from);
  void MergeFrom(const AllocateResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.AMCommandProto a_m_command = 1;
  inline bool has_a_m_command() const;
  inline void clear_a_m_command();
  static const int kAMCommandFieldNumber = 1;
  inline ::hadoop::yarn::AMCommandProto a_m_command() const;
  inline void set_a_m_command(::hadoop::yarn::AMCommandProto value);

  // optional int32 response_id = 2;
  inline bool has_response_id() const;
  inline void clear_response_id();
  static const int kResponseIdFieldNumber = 2;
  inline ::google::protobuf::int32 response_id() const;
  inline void set_response_id(::google::protobuf::int32 value);

  // repeated .hadoop.yarn.ContainerProto allocated_containers = 3;
  inline int allocated_containers_size() const;
  inline void clear_allocated_containers();
  static const int kAllocatedContainersFieldNumber = 3;
  inline const ::hadoop::yarn::ContainerProto& allocated_containers(int index) const;
  inline ::hadoop::yarn::ContainerProto* mutable_allocated_containers(int index);
  inline ::hadoop::yarn::ContainerProto* add_allocated_containers();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerProto >&
      allocated_containers() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerProto >*
      mutable_allocated_containers();

  // repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;
  inline int completed_container_statuses_size() const;
  inline void clear_completed_container_statuses();
  static const int kCompletedContainerStatusesFieldNumber = 4;
  inline const ::hadoop::yarn::ContainerStatusProto& completed_container_statuses(int index) const;
  inline ::hadoop::yarn::ContainerStatusProto* mutable_completed_container_statuses(int index);
  inline ::hadoop::yarn::ContainerStatusProto* add_completed_container_statuses();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerStatusProto >&
      completed_container_statuses() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerStatusProto >*
      mutable_completed_container_statuses();

  // optional .hadoop.yarn.ResourceProto limit = 5;
  inline bool has_limit() const;
  inline void clear_limit();
  static const int kLimitFieldNumber = 5;
  inline const ::hadoop::yarn::ResourceProto& limit() const;
  inline ::hadoop::yarn::ResourceProto* mutable_limit();
  inline ::hadoop::yarn::ResourceProto* release_limit();
  inline void set_allocated_limit(::hadoop::yarn::ResourceProto* limit);

  // repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;
  inline int updated_nodes_size() const;
  inline void clear_updated_nodes();
  static const int kUpdatedNodesFieldNumber = 6;
  inline const ::hadoop::yarn::NodeReportProto& updated_nodes(int index) const;
  inline ::hadoop::yarn::NodeReportProto* mutable_updated_nodes(int index);
  inline ::hadoop::yarn::NodeReportProto* add_updated_nodes();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NodeReportProto >&
      updated_nodes() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NodeReportProto >*
      mutable_updated_nodes();

  // optional int32 num_cluster_nodes = 7;
  inline bool has_num_cluster_nodes() const;
  inline void clear_num_cluster_nodes();
  static const int kNumClusterNodesFieldNumber = 7;
  inline ::google::protobuf::int32 num_cluster_nodes() const;
  inline void set_num_cluster_nodes(::google::protobuf::int32 value);

  // optional .hadoop.yarn.PreemptionMessageProto preempt = 8;
  inline bool has_preempt() const;
  inline void clear_preempt();
  static const int kPreemptFieldNumber = 8;
  inline const ::hadoop::yarn::PreemptionMessageProto& preempt() const;
  inline ::hadoop::yarn::PreemptionMessageProto* mutable_preempt();
  inline ::hadoop::yarn::PreemptionMessageProto* release_preempt();
  inline void set_allocated_preempt(::hadoop::yarn::PreemptionMessageProto* preempt);

  // repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;
  inline int nm_tokens_size() const;
  inline void clear_nm_tokens();
  static const int kNmTokensFieldNumber = 9;
  inline const ::hadoop::yarn::NMTokenProto& nm_tokens(int index) const;
  inline ::hadoop::yarn::NMTokenProto* mutable_nm_tokens(int index);
  inline ::hadoop::yarn::NMTokenProto* add_nm_tokens();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NMTokenProto >&
      nm_tokens() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NMTokenProto >*
      mutable_nm_tokens();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.AllocateResponseProto)
 private:
  inline void set_has_a_m_command();
  inline void clear_has_a_m_command();
  inline void set_has_response_id();
  inline void clear_has_response_id();
  inline void set_has_limit();
  inline void clear_has_limit();
  inline void set_has_num_cluster_nodes();
  inline void clear_has_num_cluster_nodes();
  inline void set_has_preempt();
  inline void clear_has_preempt();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  int a_m_command_;
  ::google::protobuf::int32 response_id_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerProto > allocated_containers_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerStatusProto > completed_container_statuses_;
  ::hadoop::yarn::ResourceProto* limit_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NodeReportProto > updated_nodes_;
  ::hadoop::yarn::PreemptionMessageProto* preempt_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NMTokenProto > nm_tokens_;
  ::google::protobuf::int32 num_cluster_nodes_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(9 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static AllocateResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class GetNewApplicationRequestProto : public ::google::protobuf::Message {
 public:
  GetNewApplicationRequestProto();
  virtual ~GetNewApplicationRequestProto();

  GetNewApplicationRequestProto(const GetNewApplicationRequestProto& from);

  inline GetNewApplicationRequestProto& operator=(const GetNewApplicationRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetNewApplicationRequestProto& default_instance();

  void Swap(GetNewApplicationRequestProto* other);

  // implements Message ----------------------------------------------

  GetNewApplicationRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetNewApplicationRequestProto& from);
  void MergeFrom(const GetNewApplicationRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetNewApplicationRequestProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;


  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[1];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetNewApplicationRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class GetNewApplicationResponseProto : public ::google::protobuf::Message {
 public:
  GetNewApplicationResponseProto();
  virtual ~GetNewApplicationResponseProto();

  GetNewApplicationResponseProto(const GetNewApplicationResponseProto& from);

  inline GetNewApplicationResponseProto& operator=(const GetNewApplicationResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetNewApplicationResponseProto& default_instance();

  void Swap(GetNewApplicationResponseProto* other);

  // implements Message ----------------------------------------------

  GetNewApplicationResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetNewApplicationResponseProto& from);
  void MergeFrom(const GetNewApplicationResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
  inline bool has_application_id() const;
  inline void clear_application_id();
  static const int kApplicationIdFieldNumber = 1;
  inline const ::hadoop::yarn::ApplicationIdProto& application_id() const;
  inline ::hadoop::yarn::ApplicationIdProto* mutable_application_id();
  inline ::hadoop::yarn::ApplicationIdProto* release_application_id();
  inline void set_allocated_application_id(::hadoop::yarn::ApplicationIdProto* application_id);

  // optional .hadoop.yarn.ResourceProto maximumCapability = 2;
  inline bool has_maximumcapability() const;
  inline void clear_maximumcapability();
  static const int kMaximumCapabilityFieldNumber = 2;
  inline const ::hadoop::yarn::ResourceProto& maximumcapability() const;
  inline ::hadoop::yarn::ResourceProto* mutable_maximumcapability();
  inline ::hadoop::yarn::ResourceProto* release_maximumcapability();
  inline void set_allocated_maximumcapability(::hadoop::yarn::ResourceProto* maximumcapability);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetNewApplicationResponseProto)
 private:
  inline void set_has_application_id();
  inline void clear_has_application_id();
  inline void set_has_maximumcapability();
  inline void clear_has_maximumcapability();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ApplicationIdProto* application_id_;
  ::hadoop::yarn::ResourceProto* maximumcapability_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetNewApplicationResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class GetApplicationReportRequestProto : public ::google::protobuf::Message {
 public:
  GetApplicationReportRequestProto();
  virtual ~GetApplicationReportRequestProto();

  GetApplicationReportRequestProto(const GetApplicationReportRequestProto& from);

  inline GetApplicationReportRequestProto& operator=(const GetApplicationReportRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetApplicationReportRequestProto& default_instance();

  void Swap(GetApplicationReportRequestProto* other);

  // implements Message ----------------------------------------------

  GetApplicationReportRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetApplicationReportRequestProto& from);
  void MergeFrom(const GetApplicationReportRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
  inline bool has_application_id() const;
  inline void clear_application_id();
  static const int kApplicationIdFieldNumber = 1;
  inline const ::hadoop::yarn::ApplicationIdProto& application_id() const;
  inline ::hadoop::yarn::ApplicationIdProto* mutable_application_id();
  inline ::hadoop::yarn::ApplicationIdProto* release_application_id();
  inline void set_allocated_application_id(::hadoop::yarn::ApplicationIdProto* application_id);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetApplicationReportRequestProto)
 private:
  inline void set_has_application_id();
  inline void clear_has_application_id();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ApplicationIdProto* application_id_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetApplicationReportRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class GetApplicationReportResponseProto : public ::google::protobuf::Message {
 public:
  GetApplicationReportResponseProto();
  virtual ~GetApplicationReportResponseProto();

  GetApplicationReportResponseProto(const GetApplicationReportResponseProto& from);

  inline GetApplicationReportResponseProto& operator=(const GetApplicationReportResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetApplicationReportResponseProto& default_instance();

  void Swap(GetApplicationReportResponseProto* other);

  // implements Message ----------------------------------------------

  GetApplicationReportResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetApplicationReportResponseProto& from);
  void MergeFrom(const GetApplicationReportResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ApplicationReportProto application_report = 1;
  inline bool has_application_report() const;
  inline void clear_application_report();
  static const int kApplicationReportFieldNumber = 1;
  inline const ::hadoop::yarn::ApplicationReportProto& application_report() const;
  inline ::hadoop::yarn::ApplicationReportProto* mutable_application_report();
  inline ::hadoop::yarn::ApplicationReportProto* release_application_report();
  inline void set_allocated_application_report(::hadoop::yarn::ApplicationReportProto* application_report);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetApplicationReportResponseProto)
 private:
  inline void set_has_application_report();
  inline void clear_has_application_report();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ApplicationReportProto* application_report_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetApplicationReportResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class SubmitApplicationRequestProto : public ::google::protobuf::Message {
 public:
  SubmitApplicationRequestProto();
  virtual ~SubmitApplicationRequestProto();

  SubmitApplicationRequestProto(const SubmitApplicationRequestProto& from);

  inline SubmitApplicationRequestProto& operator=(const SubmitApplicationRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SubmitApplicationRequestProto& default_instance();

  void Swap(SubmitApplicationRequestProto* other);

  // implements Message ----------------------------------------------

  SubmitApplicationRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const SubmitApplicationRequestProto& from);
  void MergeFrom(const SubmitApplicationRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;
  inline bool has_application_submission_context() const;
  inline void clear_application_submission_context();
  static const int kApplicationSubmissionContextFieldNumber = 1;
  inline const ::hadoop::yarn::ApplicationSubmissionContextProto& application_submission_context() const;
  inline ::hadoop::yarn::ApplicationSubmissionContextProto* mutable_application_submission_context();
  inline ::hadoop::yarn::ApplicationSubmissionContextProto* release_application_submission_context();
  inline void set_allocated_application_submission_context(::hadoop::yarn::ApplicationSubmissionContextProto* application_submission_context);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.SubmitApplicationRequestProto)
 private:
  inline void set_has_application_submission_context();
  inline void clear_has_application_submission_context();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ApplicationSubmissionContextProto* application_submission_context_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static SubmitApplicationRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class SubmitApplicationResponseProto : public ::google::protobuf::Message {
 public:
  SubmitApplicationResponseProto();
  virtual ~SubmitApplicationResponseProto();

  SubmitApplicationResponseProto(const SubmitApplicationResponseProto& from);

  inline SubmitApplicationResponseProto& operator=(const SubmitApplicationResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SubmitApplicationResponseProto& default_instance();

  void Swap(SubmitApplicationResponseProto* other);

  // implements Message ----------------------------------------------

  SubmitApplicationResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const SubmitApplicationResponseProto& from);
  void MergeFrom(const SubmitApplicationResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // @@protoc_insertion_point(class_scope:hadoop.yarn.SubmitApplicationResponseProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;


  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[1];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static SubmitApplicationResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class KillApplicationRequestProto : public ::google::protobuf::Message {
 public:
  KillApplicationRequestProto();
  virtual ~KillApplicationRequestProto();

  KillApplicationRequestProto(const KillApplicationRequestProto& from);

  inline KillApplicationRequestProto& operator=(const KillApplicationRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const KillApplicationRequestProto& default_instance();

  void Swap(KillApplicationRequestProto* other);

  // implements Message ----------------------------------------------

  KillApplicationRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const KillApplicationRequestProto& from);
  void MergeFrom(const KillApplicationRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
  inline bool has_application_id() const;
  inline void clear_application_id();
  static const int kApplicationIdFieldNumber = 1;
  inline const ::hadoop::yarn::ApplicationIdProto& application_id() const;
  inline ::hadoop::yarn::ApplicationIdProto* mutable_application_id();
  inline ::hadoop::yarn::ApplicationIdProto* release_application_id();
  inline void set_allocated_application_id(::hadoop::yarn::ApplicationIdProto* application_id);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.KillApplicationRequestProto)
 private:
  inline void set_has_application_id();
  inline void clear_has_application_id();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ApplicationIdProto* application_id_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static KillApplicationRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class KillApplicationResponseProto : public ::google::protobuf::Message {
 public:
  KillApplicationResponseProto();
  virtual ~KillApplicationResponseProto();

  KillApplicationResponseProto(const KillApplicationResponseProto& from);

  inline KillApplicationResponseProto& operator=(const KillApplicationResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const KillApplicationResponseProto& default_instance();

  void Swap(KillApplicationResponseProto* other);

  // implements Message ----------------------------------------------

  KillApplicationResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const KillApplicationResponseProto& from);
  void MergeFrom(const KillApplicationResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // @@protoc_insertion_point(class_scope:hadoop.yarn.KillApplicationResponseProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;


  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[1];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static KillApplicationResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class GetClusterMetricsRequestProto : public ::google::protobuf::Message {
 public:
  GetClusterMetricsRequestProto();
  virtual ~GetClusterMetricsRequestProto();

  GetClusterMetricsRequestProto(const GetClusterMetricsRequestProto& from);

  inline GetClusterMetricsRequestProto& operator=(const GetClusterMetricsRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetClusterMetricsRequestProto& default_instance();

  void Swap(GetClusterMetricsRequestProto* other);

  // implements Message ----------------------------------------------

  GetClusterMetricsRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetClusterMetricsRequestProto& from);
  void MergeFrom(const GetClusterMetricsRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetClusterMetricsRequestProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;


  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[1];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetClusterMetricsRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class GetClusterMetricsResponseProto : public ::google::protobuf::Message {
 public:
  GetClusterMetricsResponseProto();
  virtual ~GetClusterMetricsResponseProto();

  GetClusterMetricsResponseProto(const GetClusterMetricsResponseProto& from);

  inline GetClusterMetricsResponseProto& operator=(const GetClusterMetricsResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetClusterMetricsResponseProto& default_instance();

  void Swap(GetClusterMetricsResponseProto* other);

  // implements Message ----------------------------------------------

  GetClusterMetricsResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetClusterMetricsResponseProto& from);
  void MergeFrom(const GetClusterMetricsResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;
  inline bool has_cluster_metrics() const;
  inline void clear_cluster_metrics();
  static const int kClusterMetricsFieldNumber = 1;
  inline const ::hadoop::yarn::YarnClusterMetricsProto& cluster_metrics() const;
  inline ::hadoop::yarn::YarnClusterMetricsProto* mutable_cluster_metrics();
  inline ::hadoop::yarn::YarnClusterMetricsProto* release_cluster_metrics();
  inline void set_allocated_cluster_metrics(::hadoop::yarn::YarnClusterMetricsProto* cluster_metrics);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetClusterMetricsResponseProto)
 private:
  inline void set_has_cluster_metrics();
  inline void clear_has_cluster_metrics();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::YarnClusterMetricsProto* cluster_metrics_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetClusterMetricsResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class GetApplicationsRequestProto : public ::google::protobuf::Message {
 public:
  GetApplicationsRequestProto();
  virtual ~GetApplicationsRequestProto();

  GetApplicationsRequestProto(const GetApplicationsRequestProto& from);

  inline GetApplicationsRequestProto& operator=(const GetApplicationsRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetApplicationsRequestProto& default_instance();

  void Swap(GetApplicationsRequestProto* other);

  // implements Message ----------------------------------------------

  GetApplicationsRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetApplicationsRequestProto& from);
  void MergeFrom(const GetApplicationsRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated string application_types = 1;
  inline int application_types_size() const;
  inline void clear_application_types();
  static const int kApplicationTypesFieldNumber = 1;
  inline const ::std::string& application_types(int index) const;
  inline ::std::string* mutable_application_types(int index);
  inline void set_application_types(int index, const ::std::string& value);
  inline void set_application_types(int index, const char* value);
  inline void set_application_types(int index, const char* value, size_t size);
  inline ::std::string* add_application_types();
  inline void add_application_types(const ::std::string& value);
  inline void add_application_types(const char* value);
  inline void add_application_types(const char* value, size_t size);
  inline const ::google::protobuf::RepeatedPtrField< ::std::string>& application_types() const;
  inline ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_application_types();

  // repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;
  inline int application_states_size() const;
  inline void clear_application_states();
  static const int kApplicationStatesFieldNumber = 2;
  inline ::hadoop::yarn::YarnApplicationStateProto application_states(int index) const;
  inline void set_application_states(int index, ::hadoop::yarn::YarnApplicationStateProto value);
  inline void add_application_states(::hadoop::yarn::YarnApplicationStateProto value);
  inline const ::google::protobuf::RepeatedField<int>& application_states() const;
  inline ::google::protobuf::RepeatedField<int>* mutable_application_states();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetApplicationsRequestProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::std::string> application_types_;
  ::google::protobuf::RepeatedField<int> application_states_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetApplicationsRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class GetApplicationsResponseProto : public ::google::protobuf::Message {
 public:
  GetApplicationsResponseProto();
  virtual ~GetApplicationsResponseProto();

  GetApplicationsResponseProto(const GetApplicationsResponseProto& from);

  inline GetApplicationsResponseProto& operator=(const GetApplicationsResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetApplicationsResponseProto& default_instance();

  void Swap(GetApplicationsResponseProto* other);

  // implements Message ----------------------------------------------

  GetApplicationsResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetApplicationsResponseProto& from);
  void MergeFrom(const GetApplicationsResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.ApplicationReportProto applications = 1;
  inline int applications_size() const;
  inline void clear_applications();
  static const int kApplicationsFieldNumber = 1;
  inline const ::hadoop::yarn::ApplicationReportProto& applications(int index) const;
  inline ::hadoop::yarn::ApplicationReportProto* mutable_applications(int index);
  inline ::hadoop::yarn::ApplicationReportProto* add_applications();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationReportProto >&
      applications() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationReportProto >*
      mutable_applications();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetApplicationsResponseProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationReportProto > applications_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetApplicationsResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class GetClusterNodesRequestProto : public ::google::protobuf::Message {
 public:
  GetClusterNodesRequestProto();
  virtual ~GetClusterNodesRequestProto();

  GetClusterNodesRequestProto(const GetClusterNodesRequestProto& from);

  inline GetClusterNodesRequestProto& operator=(const GetClusterNodesRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetClusterNodesRequestProto& default_instance();

  void Swap(GetClusterNodesRequestProto* other);

  // implements Message ----------------------------------------------

  GetClusterNodesRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetClusterNodesRequestProto& from);
  void MergeFrom(const GetClusterNodesRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.NodeStateProto nodeStates = 1;
  inline int nodestates_size() const;
  inline void clear_nodestates();
  static const int kNodeStatesFieldNumber = 1;
  inline ::hadoop::yarn::NodeStateProto nodestates(int index) const;
  inline void set_nodestates(int index, ::hadoop::yarn::NodeStateProto value);
  inline void add_nodestates(::hadoop::yarn::NodeStateProto value);
  inline const ::google::protobuf::RepeatedField<int>& nodestates() const;
  inline ::google::protobuf::RepeatedField<int>* mutable_nodestates();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetClusterNodesRequestProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedField<int> nodestates_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetClusterNodesRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class GetClusterNodesResponseProto : public ::google::protobuf::Message {
 public:
  GetClusterNodesResponseProto();
  virtual ~GetClusterNodesResponseProto();

  GetClusterNodesResponseProto(const GetClusterNodesResponseProto& from);

  inline GetClusterNodesResponseProto& operator=(const GetClusterNodesResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetClusterNodesResponseProto& default_instance();

  void Swap(GetClusterNodesResponseProto* other);

  // implements Message ----------------------------------------------

  GetClusterNodesResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetClusterNodesResponseProto& from);
  void MergeFrom(const GetClusterNodesResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.NodeReportProto nodeReports = 1;
  inline int nodereports_size() const;
  inline void clear_nodereports();
  static const int kNodeReportsFieldNumber = 1;
  inline const ::hadoop::yarn::NodeReportProto& nodereports(int index) const;
  inline ::hadoop::yarn::NodeReportProto* mutable_nodereports(int index);
  inline ::hadoop::yarn::NodeReportProto* add_nodereports();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NodeReportProto >&
      nodereports() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NodeReportProto >*
      mutable_nodereports();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetClusterNodesResponseProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NodeReportProto > nodereports_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetClusterNodesResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class GetQueueInfoRequestProto : public ::google::protobuf::Message {
 public:
  GetQueueInfoRequestProto();
  virtual ~GetQueueInfoRequestProto();

  GetQueueInfoRequestProto(const GetQueueInfoRequestProto& from);

  inline GetQueueInfoRequestProto& operator=(const GetQueueInfoRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetQueueInfoRequestProto& default_instance();

  void Swap(GetQueueInfoRequestProto* other);

  // implements Message ----------------------------------------------

  GetQueueInfoRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetQueueInfoRequestProto& from);
  void MergeFrom(const GetQueueInfoRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string queueName = 1;
  inline bool has_queuename() const;
  inline void clear_queuename();
  static const int kQueueNameFieldNumber = 1;
  inline const ::std::string& queuename() const;
  inline void set_queuename(const ::std::string& value);
  inline void set_queuename(const char* value);
  inline void set_queuename(const char* value, size_t size);
  inline ::std::string* mutable_queuename();
  inline ::std::string* release_queuename();
  inline void set_allocated_queuename(::std::string* queuename);

  // optional bool includeApplications = 2;
  inline bool has_includeapplications() const;
  inline void clear_includeapplications();
  static const int kIncludeApplicationsFieldNumber = 2;
  inline bool includeapplications() const;
  inline void set_includeapplications(bool value);

  // optional bool includeChildQueues = 3;
  inline bool has_includechildqueues() const;
  inline void clear_includechildqueues();
  static const int kIncludeChildQueuesFieldNumber = 3;
  inline bool includechildqueues() const;
  inline void set_includechildqueues(bool value);

  // optional bool recursive = 4;
  inline bool has_recursive() const;
  inline void clear_recursive();
  static const int kRecursiveFieldNumber = 4;
  inline bool recursive() const;
  inline void set_recursive(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetQueueInfoRequestProto)
 private:
  inline void set_has_queuename();
  inline void clear_has_queuename();
  inline void set_has_includeapplications();
  inline void clear_has_includeapplications();
  inline void set_has_includechildqueues();
  inline void clear_has_includechildqueues();
  inline void set_has_recursive();
  inline void clear_has_recursive();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::std::string* queuename_;
  bool includeapplications_;
  bool includechildqueues_;
  bool recursive_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(4 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetQueueInfoRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class GetQueueInfoResponseProto : public ::google::protobuf::Message {
 public:
  GetQueueInfoResponseProto();
  virtual ~GetQueueInfoResponseProto();

  GetQueueInfoResponseProto(const GetQueueInfoResponseProto& from);

  inline GetQueueInfoResponseProto& operator=(const GetQueueInfoResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetQueueInfoResponseProto& default_instance();

  void Swap(GetQueueInfoResponseProto* other);

  // implements Message ----------------------------------------------

  GetQueueInfoResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetQueueInfoResponseProto& from);
  void MergeFrom(const GetQueueInfoResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.QueueInfoProto queueInfo = 1;
  inline bool has_queueinfo() const;
  inline void clear_queueinfo();
  static const int kQueueInfoFieldNumber = 1;
  inline const ::hadoop::yarn::QueueInfoProto& queueinfo() const;
  inline ::hadoop::yarn::QueueInfoProto* mutable_queueinfo();
  inline ::hadoop::yarn::QueueInfoProto* release_queueinfo();
  inline void set_allocated_queueinfo(::hadoop::yarn::QueueInfoProto* queueinfo);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetQueueInfoResponseProto)
 private:
  inline void set_has_queueinfo();
  inline void clear_has_queueinfo();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::QueueInfoProto* queueinfo_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetQueueInfoResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class GetQueueUserAclsInfoRequestProto : public ::google::protobuf::Message {
 public:
  GetQueueUserAclsInfoRequestProto();
  virtual ~GetQueueUserAclsInfoRequestProto();

  GetQueueUserAclsInfoRequestProto(const GetQueueUserAclsInfoRequestProto& from);

  inline GetQueueUserAclsInfoRequestProto& operator=(const GetQueueUserAclsInfoRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetQueueUserAclsInfoRequestProto& default_instance();

  void Swap(GetQueueUserAclsInfoRequestProto* other);

  // implements Message ----------------------------------------------

  GetQueueUserAclsInfoRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetQueueUserAclsInfoRequestProto& from);
  void MergeFrom(const GetQueueUserAclsInfoRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetQueueUserAclsInfoRequestProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;


  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[1];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetQueueUserAclsInfoRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class GetQueueUserAclsInfoResponseProto : public ::google::protobuf::Message {
 public:
  GetQueueUserAclsInfoResponseProto();
  virtual ~GetQueueUserAclsInfoResponseProto();

  GetQueueUserAclsInfoResponseProto(const GetQueueUserAclsInfoResponseProto& from);

  inline GetQueueUserAclsInfoResponseProto& operator=(const GetQueueUserAclsInfoResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetQueueUserAclsInfoResponseProto& default_instance();

  void Swap(GetQueueUserAclsInfoResponseProto* other);

  // implements Message ----------------------------------------------

  GetQueueUserAclsInfoResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetQueueUserAclsInfoResponseProto& from);
  void MergeFrom(const GetQueueUserAclsInfoResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;
  inline int queueuseracls_size() const;
  inline void clear_queueuseracls();
  static const int kQueueUserAclsFieldNumber = 1;
  inline const ::hadoop::yarn::QueueUserACLInfoProto& queueuseracls(int index) const;
  inline ::hadoop::yarn::QueueUserACLInfoProto* mutable_queueuseracls(int index);
  inline ::hadoop::yarn::QueueUserACLInfoProto* add_queueuseracls();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::QueueUserACLInfoProto >&
      queueuseracls() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::QueueUserACLInfoProto >*
      mutable_queueuseracls();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetQueueUserAclsInfoResponseProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::QueueUserACLInfoProto > queueuseracls_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetQueueUserAclsInfoResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class StartContainerRequestProto : public ::google::protobuf::Message {
 public:
  StartContainerRequestProto();
  virtual ~StartContainerRequestProto();

  StartContainerRequestProto(const StartContainerRequestProto& from);

  inline StartContainerRequestProto& operator=(const StartContainerRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StartContainerRequestProto& default_instance();

  void Swap(StartContainerRequestProto* other);

  // implements Message ----------------------------------------------

  StartContainerRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StartContainerRequestProto& from);
  void MergeFrom(const StartContainerRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;
  inline bool has_container_launch_context() const;
  inline void clear_container_launch_context();
  static const int kContainerLaunchContextFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerLaunchContextProto& container_launch_context() const;
  inline ::hadoop::yarn::ContainerLaunchContextProto* mutable_container_launch_context();
  inline ::hadoop::yarn::ContainerLaunchContextProto* release_container_launch_context();
  inline void set_allocated_container_launch_context(::hadoop::yarn::ContainerLaunchContextProto* container_launch_context);

  // optional .hadoop.common.TokenProto container_token = 2;
  inline bool has_container_token() const;
  inline void clear_container_token();
  static const int kContainerTokenFieldNumber = 2;
  inline const ::hadoop::common::TokenProto& container_token() const;
  inline ::hadoop::common::TokenProto* mutable_container_token();
  inline ::hadoop::common::TokenProto* release_container_token();
  inline void set_allocated_container_token(::hadoop::common::TokenProto* container_token);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.StartContainerRequestProto)
 private:
  inline void set_has_container_launch_context();
  inline void clear_has_container_launch_context();
  inline void set_has_container_token();
  inline void clear_has_container_token();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ContainerLaunchContextProto* container_launch_context_;
  ::hadoop::common::TokenProto* container_token_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static StartContainerRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class StartContainerResponseProto : public ::google::protobuf::Message {
 public:
  StartContainerResponseProto();
  virtual ~StartContainerResponseProto();

  StartContainerResponseProto(const StartContainerResponseProto& from);

  inline StartContainerResponseProto& operator=(const StartContainerResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StartContainerResponseProto& default_instance();

  void Swap(StartContainerResponseProto* other);

  // implements Message ----------------------------------------------

  StartContainerResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StartContainerResponseProto& from);
  void MergeFrom(const StartContainerResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;
  inline int services_meta_data_size() const;
  inline void clear_services_meta_data();
  static const int kServicesMetaDataFieldNumber = 1;
  inline const ::hadoop::yarn::StringBytesMapProto& services_meta_data(int index) const;
  inline ::hadoop::yarn::StringBytesMapProto* mutable_services_meta_data(int index);
  inline ::hadoop::yarn::StringBytesMapProto* add_services_meta_data();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto >&
      services_meta_data() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto >*
      mutable_services_meta_data();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.StartContainerResponseProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto > services_meta_data_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static StartContainerResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class StopContainerRequestProto : public ::google::protobuf::Message {
 public:
  StopContainerRequestProto();
  virtual ~StopContainerRequestProto();

  StopContainerRequestProto(const StopContainerRequestProto& from);

  inline StopContainerRequestProto& operator=(const StopContainerRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StopContainerRequestProto& default_instance();

  void Swap(StopContainerRequestProto* other);

  // implements Message ----------------------------------------------

  StopContainerRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StopContainerRequestProto& from);
  void MergeFrom(const StopContainerRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ContainerIdProto container_id = 1;
  inline bool has_container_id() const;
  inline void clear_container_id();
  static const int kContainerIdFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerIdProto& container_id() const;
  inline ::hadoop::yarn::ContainerIdProto* mutable_container_id();
  inline ::hadoop::yarn::ContainerIdProto* release_container_id();
  inline void set_allocated_container_id(::hadoop::yarn::ContainerIdProto* container_id);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.StopContainerRequestProto)
 private:
  inline void set_has_container_id();
  inline void clear_has_container_id();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ContainerIdProto* container_id_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static StopContainerRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class StopContainerResponseProto : public ::google::protobuf::Message {
 public:
  StopContainerResponseProto();
  virtual ~StopContainerResponseProto();

  StopContainerResponseProto(const StopContainerResponseProto& from);

  inline StopContainerResponseProto& operator=(const StopContainerResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StopContainerResponseProto& default_instance();

  void Swap(StopContainerResponseProto* other);

  // implements Message ----------------------------------------------

  StopContainerResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StopContainerResponseProto& from);
  void MergeFrom(const StopContainerResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // @@protoc_insertion_point(class_scope:hadoop.yarn.StopContainerResponseProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;


  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[1];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static StopContainerResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class GetContainerStatusRequestProto : public ::google::protobuf::Message {
 public:
  GetContainerStatusRequestProto();
  virtual ~GetContainerStatusRequestProto();

  GetContainerStatusRequestProto(const GetContainerStatusRequestProto& from);

  inline GetContainerStatusRequestProto& operator=(const GetContainerStatusRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetContainerStatusRequestProto& default_instance();

  void Swap(GetContainerStatusRequestProto* other);

  // implements Message ----------------------------------------------

  GetContainerStatusRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetContainerStatusRequestProto& from);
  void MergeFrom(const GetContainerStatusRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ContainerIdProto container_id = 1;
  inline bool has_container_id() const;
  inline void clear_container_id();
  static const int kContainerIdFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerIdProto& container_id() const;
  inline ::hadoop::yarn::ContainerIdProto* mutable_container_id();
  inline ::hadoop::yarn::ContainerIdProto* release_container_id();
  inline void set_allocated_container_id(::hadoop::yarn::ContainerIdProto* container_id);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetContainerStatusRequestProto)
 private:
  inline void set_has_container_id();
  inline void clear_has_container_id();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ContainerIdProto* container_id_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetContainerStatusRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class GetContainerStatusResponseProto : public ::google::protobuf::Message {
 public:
  GetContainerStatusResponseProto();
  virtual ~GetContainerStatusResponseProto();

  GetContainerStatusResponseProto(const GetContainerStatusResponseProto& from);

  inline GetContainerStatusResponseProto& operator=(const GetContainerStatusResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetContainerStatusResponseProto& default_instance();

  void Swap(GetContainerStatusResponseProto* other);

  // implements Message ----------------------------------------------

  GetContainerStatusResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetContainerStatusResponseProto& from);
  void MergeFrom(const GetContainerStatusResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ContainerStatusProto status = 1;
  inline bool has_status() const;
  inline void clear_status();
  static const int kStatusFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerStatusProto& status() const;
  inline ::hadoop::yarn::ContainerStatusProto* mutable_status();
  inline ::hadoop::yarn::ContainerStatusProto* release_status();
  inline void set_allocated_status(::hadoop::yarn::ContainerStatusProto* status);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetContainerStatusResponseProto)
 private:
  inline void set_has_status();
  inline void clear_has_status();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ContainerStatusProto* status_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetContainerStatusResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class StartContainersRequestProto : public ::google::protobuf::Message {
 public:
  StartContainersRequestProto();
  virtual ~StartContainersRequestProto();

  StartContainersRequestProto(const StartContainersRequestProto& from);

  inline StartContainersRequestProto& operator=(const StartContainersRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StartContainersRequestProto& default_instance();

  void Swap(StartContainersRequestProto* other);

  // implements Message ----------------------------------------------

  StartContainersRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StartContainersRequestProto& from);
  void MergeFrom(const StartContainersRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;
  inline int start_container_request_size() const;
  inline void clear_start_container_request();
  static const int kStartContainerRequestFieldNumber = 1;
  inline const ::hadoop::yarn::StartContainerRequestProto& start_container_request(int index) const;
  inline ::hadoop::yarn::StartContainerRequestProto* mutable_start_container_request(int index);
  inline ::hadoop::yarn::StartContainerRequestProto* add_start_container_request();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StartContainerRequestProto >&
      start_container_request() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StartContainerRequestProto >*
      mutable_start_container_request();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.StartContainersRequestProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StartContainerRequestProto > start_container_request_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static StartContainersRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class ContainerExceptionMapProto : public ::google::protobuf::Message {
 public:
  ContainerExceptionMapProto();
  virtual ~ContainerExceptionMapProto();

  ContainerExceptionMapProto(const ContainerExceptionMapProto& from);

  inline ContainerExceptionMapProto& operator=(const ContainerExceptionMapProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ContainerExceptionMapProto& default_instance();

  void Swap(ContainerExceptionMapProto* other);

  // implements Message ----------------------------------------------

  ContainerExceptionMapProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const ContainerExceptionMapProto& from);
  void MergeFrom(const ContainerExceptionMapProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.yarn.ContainerIdProto container_id = 1;
  inline bool has_container_id() const;
  inline void clear_container_id();
  static const int kContainerIdFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerIdProto& container_id() const;
  inline ::hadoop::yarn::ContainerIdProto* mutable_container_id();
  inline ::hadoop::yarn::ContainerIdProto* release_container_id();
  inline void set_allocated_container_id(::hadoop::yarn::ContainerIdProto* container_id);

  // optional .hadoop.yarn.SerializedExceptionProto exception = 2;
  inline bool has_exception() const;
  inline void clear_exception();
  static const int kExceptionFieldNumber = 2;
  inline const ::hadoop::yarn::SerializedExceptionProto& exception() const;
  inline ::hadoop::yarn::SerializedExceptionProto* mutable_exception();
  inline ::hadoop::yarn::SerializedExceptionProto* release_exception();
  inline void set_allocated_exception(::hadoop::yarn::SerializedExceptionProto* exception);

  // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerExceptionMapProto)
 private:
  inline void set_has_container_id();
  inline void clear_has_container_id();
  inline void set_has_exception();
  inline void clear_has_exception();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::hadoop::yarn::ContainerIdProto* container_id_;
  ::hadoop::yarn::SerializedExceptionProto* exception_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static ContainerExceptionMapProto* default_instance_;
};
// -------------------------------------------------------------------

class StartContainersResponseProto : public ::google::protobuf::Message {
 public:
  StartContainersResponseProto();
  virtual ~StartContainersResponseProto();

  StartContainersResponseProto(const StartContainersResponseProto& from);

  inline StartContainersResponseProto& operator=(const StartContainersResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StartContainersResponseProto& default_instance();

  void Swap(StartContainersResponseProto* other);

  // implements Message ----------------------------------------------

  StartContainersResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StartContainersResponseProto& from);
  void MergeFrom(const StartContainersResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;
  inline int services_meta_data_size() const;
  inline void clear_services_meta_data();
  static const int kServicesMetaDataFieldNumber = 1;
  inline const ::hadoop::yarn::StringBytesMapProto& services_meta_data(int index) const;
  inline ::hadoop::yarn::StringBytesMapProto* mutable_services_meta_data(int index);
  inline ::hadoop::yarn::StringBytesMapProto* add_services_meta_data();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto >&
      services_meta_data() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto >*
      mutable_services_meta_data();

  // repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;
  inline int succeeded_requests_size() const;
  inline void clear_succeeded_requests();
  static const int kSucceededRequestsFieldNumber = 2;
  inline const ::hadoop::yarn::ContainerIdProto& succeeded_requests(int index) const;
  inline ::hadoop::yarn::ContainerIdProto* mutable_succeeded_requests(int index);
  inline ::hadoop::yarn::ContainerIdProto* add_succeeded_requests();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >&
      succeeded_requests() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >*
      mutable_succeeded_requests();

  // repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;
  inline int failed_requests_size() const;
  inline void clear_failed_requests();
  static const int kFailedRequestsFieldNumber = 3;
  inline const ::hadoop::yarn::ContainerExceptionMapProto& failed_requests(int index) const;
  inline ::hadoop::yarn::ContainerExceptionMapProto* mutable_failed_requests(int index);
  inline ::hadoop::yarn::ContainerExceptionMapProto* add_failed_requests();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto >&
      failed_requests() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto >*
      mutable_failed_requests();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.StartContainersResponseProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto > services_meta_data_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto > succeeded_requests_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto > failed_requests_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(3 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static StartContainersResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class StopContainersRequestProto : public ::google::protobuf::Message {
 public:
  StopContainersRequestProto();
  virtual ~StopContainersRequestProto();

  StopContainersRequestProto(const StopContainersRequestProto& from);

  inline StopContainersRequestProto& operator=(const StopContainersRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StopContainersRequestProto& default_instance();

  void Swap(StopContainersRequestProto* other);

  // implements Message ----------------------------------------------

  StopContainersRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StopContainersRequestProto& from);
  void MergeFrom(const StopContainersRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.ContainerIdProto container_id = 1;
  inline int container_id_size() const;
  inline void clear_container_id();
  static const int kContainerIdFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerIdProto& container_id(int index) const;
  inline ::hadoop::yarn::ContainerIdProto* mutable_container_id(int index);
  inline ::hadoop::yarn::ContainerIdProto* add_container_id();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >&
      container_id() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >*
      mutable_container_id();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.StopContainersRequestProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto > container_id_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static StopContainersRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class StopContainersResponseProto : public ::google::protobuf::Message {
 public:
  StopContainersResponseProto();
  virtual ~StopContainersResponseProto();

  StopContainersResponseProto(const StopContainersResponseProto& from);

  inline StopContainersResponseProto& operator=(const StopContainersResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StopContainersResponseProto& default_instance();

  void Swap(StopContainersResponseProto* other);

  // implements Message ----------------------------------------------

  StopContainersResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const StopContainersResponseProto& from);
  void MergeFrom(const StopContainersResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;
  inline int succeeded_requests_size() const;
  inline void clear_succeeded_requests();
  static const int kSucceededRequestsFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerIdProto& succeeded_requests(int index) const;
  inline ::hadoop::yarn::ContainerIdProto* mutable_succeeded_requests(int index);
  inline ::hadoop::yarn::ContainerIdProto* add_succeeded_requests();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >&
      succeeded_requests() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >*
      mutable_succeeded_requests();

  // repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;
  inline int failed_requests_size() const;
  inline void clear_failed_requests();
  static const int kFailedRequestsFieldNumber = 2;
  inline const ::hadoop::yarn::ContainerExceptionMapProto& failed_requests(int index) const;
  inline ::hadoop::yarn::ContainerExceptionMapProto* mutable_failed_requests(int index);
  inline ::hadoop::yarn::ContainerExceptionMapProto* add_failed_requests();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto >&
      failed_requests() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto >*
      mutable_failed_requests();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.StopContainersResponseProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto > succeeded_requests_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto > failed_requests_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static StopContainersResponseProto* default_instance_;
};
// -------------------------------------------------------------------

class GetContainerStatusesRequestProto : public ::google::protobuf::Message {
 public:
  GetContainerStatusesRequestProto();
  virtual ~GetContainerStatusesRequestProto();

  GetContainerStatusesRequestProto(const GetContainerStatusesRequestProto& from);

  inline GetContainerStatusesRequestProto& operator=(const GetContainerStatusesRequestProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetContainerStatusesRequestProto& default_instance();

  void Swap(GetContainerStatusesRequestProto* other);

  // implements Message ----------------------------------------------

  GetContainerStatusesRequestProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetContainerStatusesRequestProto& from);
  void MergeFrom(const GetContainerStatusesRequestProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.ContainerIdProto container_id = 1;
  inline int container_id_size() const;
  inline void clear_container_id();
  static const int kContainerIdFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerIdProto& container_id(int index) const;
  inline ::hadoop::yarn::ContainerIdProto* mutable_container_id(int index);
  inline ::hadoop::yarn::ContainerIdProto* add_container_id();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >&
      container_id() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >*
      mutable_container_id();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetContainerStatusesRequestProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto > container_id_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(1 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetContainerStatusesRequestProto* default_instance_;
};
// -------------------------------------------------------------------

class GetContainerStatusesResponseProto : public ::google::protobuf::Message {
 public:
  GetContainerStatusesResponseProto();
  virtual ~GetContainerStatusesResponseProto();

  GetContainerStatusesResponseProto(const GetContainerStatusesResponseProto& from);

  inline GetContainerStatusesResponseProto& operator=(const GetContainerStatusesResponseProto& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const GetContainerStatusesResponseProto& default_instance();

  void Swap(GetContainerStatusesResponseProto* other);

  // implements Message ----------------------------------------------

  GetContainerStatusesResponseProto* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const GetContainerStatusesResponseProto& from);
  void MergeFrom(const GetContainerStatusesResponseProto& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:

  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.yarn.ContainerStatusProto status = 1;
  inline int status_size() const;
  inline void clear_status();
  static const int kStatusFieldNumber = 1;
  inline const ::hadoop::yarn::ContainerStatusProto& status(int index) const;
  inline ::hadoop::yarn::ContainerStatusProto* mutable_status(int index);
  inline ::hadoop::yarn::ContainerStatusProto* add_status();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerStatusProto >&
      status() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerStatusProto >*
      mutable_status();

  // repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;
  inline int failed_requests_size() const;
  inline void clear_failed_requests();
  static const int kFailedRequestsFieldNumber = 2;
  inline const ::hadoop::yarn::ContainerExceptionMapProto& failed_requests(int index) const;
  inline ::hadoop::yarn::ContainerExceptionMapProto* mutable_failed_requests(int index);
  inline ::hadoop::yarn::ContainerExceptionMapProto* add_failed_requests();
  inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto >&
      failed_requests() const;
  inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto >*
      mutable_failed_requests();

  // @@protoc_insertion_point(class_scope:hadoop.yarn.GetContainerStatusesResponseProto)
 private:

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerStatusProto > status_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto > failed_requests_;

  mutable int _cached_size_;
  ::google::protobuf::uint32 _has_bits_[(2 + 31) / 32];

  friend void  protobuf_AddDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_AssignDesc_yarn_5fservice_5fprotos_2eproto();
  friend void protobuf_ShutdownFile_yarn_5fservice_5fprotos_2eproto();

  void InitAsDefaultInstance();
  static GetContainerStatusesResponseProto* default_instance_;
};
// ===================================================================


// ===================================================================

// RegisterApplicationMasterRequestProto

// optional string host = 1;
inline bool RegisterApplicationMasterRequestProto::has_host() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void RegisterApplicationMasterRequestProto::set_has_host() {
  _has_bits_[0] |= 0x00000001u;
}
inline void RegisterApplicationMasterRequestProto::clear_has_host() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void RegisterApplicationMasterRequestProto::clear_host() {
  if (host_ != &::google::protobuf::internal::kEmptyString) {
    host_->clear();
  }
  clear_has_host();
}
inline const ::std::string& RegisterApplicationMasterRequestProto::host() const {
  return *host_;
}
inline void RegisterApplicationMasterRequestProto::set_host(const ::std::string& value) {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  host_->assign(value);
}
inline void RegisterApplicationMasterRequestProto::set_host(const char* value) {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  host_->assign(value);
}
inline void RegisterApplicationMasterRequestProto::set_host(const char* value, size_t size) {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  host_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* RegisterApplicationMasterRequestProto::mutable_host() {
  set_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    host_ = new ::std::string;
  }
  return host_;
}
inline ::std::string* RegisterApplicationMasterRequestProto::release_host() {
  clear_has_host();
  if (host_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = host_;
    host_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void RegisterApplicationMasterRequestProto::set_allocated_host(::std::string* host) {
  if (host_ != &::google::protobuf::internal::kEmptyString) {
    delete host_;
  }
  if (host) {
    set_has_host();
    host_ = host;
  } else {
    clear_has_host();
    host_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional int32 rpc_port = 2;
inline bool RegisterApplicationMasterRequestProto::has_rpc_port() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void RegisterApplicationMasterRequestProto::set_has_rpc_port() {
  _has_bits_[0] |= 0x00000002u;
}
inline void RegisterApplicationMasterRequestProto::clear_has_rpc_port() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void RegisterApplicationMasterRequestProto::clear_rpc_port() {
  rpc_port_ = 0;
  clear_has_rpc_port();
}
inline ::google::protobuf::int32 RegisterApplicationMasterRequestProto::rpc_port() const {
  return rpc_port_;
}
inline void RegisterApplicationMasterRequestProto::set_rpc_port(::google::protobuf::int32 value) {
  set_has_rpc_port();
  rpc_port_ = value;
}

// optional string tracking_url = 3;
inline bool RegisterApplicationMasterRequestProto::has_tracking_url() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void RegisterApplicationMasterRequestProto::set_has_tracking_url() {
  _has_bits_[0] |= 0x00000004u;
}
inline void RegisterApplicationMasterRequestProto::clear_has_tracking_url() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void RegisterApplicationMasterRequestProto::clear_tracking_url() {
  if (tracking_url_ != &::google::protobuf::internal::kEmptyString) {
    tracking_url_->clear();
  }
  clear_has_tracking_url();
}
inline const ::std::string& RegisterApplicationMasterRequestProto::tracking_url() const {
  return *tracking_url_;
}
inline void RegisterApplicationMasterRequestProto::set_tracking_url(const ::std::string& value) {
  set_has_tracking_url();
  if (tracking_url_ == &::google::protobuf::internal::kEmptyString) {
    tracking_url_ = new ::std::string;
  }
  tracking_url_->assign(value);
}
inline void RegisterApplicationMasterRequestProto::set_tracking_url(const char* value) {
  set_has_tracking_url();
  if (tracking_url_ == &::google::protobuf::internal::kEmptyString) {
    tracking_url_ = new ::std::string;
  }
  tracking_url_->assign(value);
}
inline void RegisterApplicationMasterRequestProto::set_tracking_url(const char* value, size_t size) {
  set_has_tracking_url();
  if (tracking_url_ == &::google::protobuf::internal::kEmptyString) {
    tracking_url_ = new ::std::string;
  }
  tracking_url_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* RegisterApplicationMasterRequestProto::mutable_tracking_url() {
  set_has_tracking_url();
  if (tracking_url_ == &::google::protobuf::internal::kEmptyString) {
    tracking_url_ = new ::std::string;
  }
  return tracking_url_;
}
inline ::std::string* RegisterApplicationMasterRequestProto::release_tracking_url() {
  clear_has_tracking_url();
  if (tracking_url_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = tracking_url_;
    tracking_url_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void RegisterApplicationMasterRequestProto::set_allocated_tracking_url(::std::string* tracking_url) {
  if (tracking_url_ != &::google::protobuf::internal::kEmptyString) {
    delete tracking_url_;
  }
  if (tracking_url) {
    set_has_tracking_url();
    tracking_url_ = tracking_url;
  } else {
    clear_has_tracking_url();
    tracking_url_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// -------------------------------------------------------------------

// RegisterApplicationMasterResponseProto

// optional .hadoop.yarn.ResourceProto maximumCapability = 1;
inline bool RegisterApplicationMasterResponseProto::has_maximumcapability() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void RegisterApplicationMasterResponseProto::set_has_maximumcapability() {
  _has_bits_[0] |= 0x00000001u;
}
inline void RegisterApplicationMasterResponseProto::clear_has_maximumcapability() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void RegisterApplicationMasterResponseProto::clear_maximumcapability() {
  if (maximumcapability_ != NULL) maximumcapability_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_maximumcapability();
}
inline const ::hadoop::yarn::ResourceProto& RegisterApplicationMasterResponseProto::maximumcapability() const {
  return maximumcapability_ != NULL ? *maximumcapability_ : *default_instance_->maximumcapability_;
}
inline ::hadoop::yarn::ResourceProto* RegisterApplicationMasterResponseProto::mutable_maximumcapability() {
  set_has_maximumcapability();
  if (maximumcapability_ == NULL) maximumcapability_ = new ::hadoop::yarn::ResourceProto;
  return maximumcapability_;
}
inline ::hadoop::yarn::ResourceProto* RegisterApplicationMasterResponseProto::release_maximumcapability() {
  clear_has_maximumcapability();
  ::hadoop::yarn::ResourceProto* temp = maximumcapability_;
  maximumcapability_ = NULL;
  return temp;
}
inline void RegisterApplicationMasterResponseProto::set_allocated_maximumcapability(::hadoop::yarn::ResourceProto* maximumcapability) {
  delete maximumcapability_;
  maximumcapability_ = maximumcapability;
  if (maximumcapability) {
    set_has_maximumcapability();
  } else {
    clear_has_maximumcapability();
  }
}

// optional bytes client_to_am_token_master_key = 2;
inline bool RegisterApplicationMasterResponseProto::has_client_to_am_token_master_key() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void RegisterApplicationMasterResponseProto::set_has_client_to_am_token_master_key() {
  _has_bits_[0] |= 0x00000002u;
}
inline void RegisterApplicationMasterResponseProto::clear_has_client_to_am_token_master_key() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void RegisterApplicationMasterResponseProto::clear_client_to_am_token_master_key() {
  if (client_to_am_token_master_key_ != &::google::protobuf::internal::kEmptyString) {
    client_to_am_token_master_key_->clear();
  }
  clear_has_client_to_am_token_master_key();
}
inline const ::std::string& RegisterApplicationMasterResponseProto::client_to_am_token_master_key() const {
  return *client_to_am_token_master_key_;
}
inline void RegisterApplicationMasterResponseProto::set_client_to_am_token_master_key(const ::std::string& value) {
  set_has_client_to_am_token_master_key();
  if (client_to_am_token_master_key_ == &::google::protobuf::internal::kEmptyString) {
    client_to_am_token_master_key_ = new ::std::string;
  }
  client_to_am_token_master_key_->assign(value);
}
inline void RegisterApplicationMasterResponseProto::set_client_to_am_token_master_key(const char* value) {
  set_has_client_to_am_token_master_key();
  if (client_to_am_token_master_key_ == &::google::protobuf::internal::kEmptyString) {
    client_to_am_token_master_key_ = new ::std::string;
  }
  client_to_am_token_master_key_->assign(value);
}
inline void RegisterApplicationMasterResponseProto::set_client_to_am_token_master_key(const void* value, size_t size) {
  set_has_client_to_am_token_master_key();
  if (client_to_am_token_master_key_ == &::google::protobuf::internal::kEmptyString) {
    client_to_am_token_master_key_ = new ::std::string;
  }
  client_to_am_token_master_key_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* RegisterApplicationMasterResponseProto::mutable_client_to_am_token_master_key() {
  set_has_client_to_am_token_master_key();
  if (client_to_am_token_master_key_ == &::google::protobuf::internal::kEmptyString) {
    client_to_am_token_master_key_ = new ::std::string;
  }
  return client_to_am_token_master_key_;
}
inline ::std::string* RegisterApplicationMasterResponseProto::release_client_to_am_token_master_key() {
  clear_has_client_to_am_token_master_key();
  if (client_to_am_token_master_key_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = client_to_am_token_master_key_;
    client_to_am_token_master_key_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void RegisterApplicationMasterResponseProto::set_allocated_client_to_am_token_master_key(::std::string* client_to_am_token_master_key) {
  if (client_to_am_token_master_key_ != &::google::protobuf::internal::kEmptyString) {
    delete client_to_am_token_master_key_;
  }
  if (client_to_am_token_master_key) {
    set_has_client_to_am_token_master_key();
    client_to_am_token_master_key_ = client_to_am_token_master_key;
  } else {
    clear_has_client_to_am_token_master_key();
    client_to_am_token_master_key_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 3;
inline int RegisterApplicationMasterResponseProto::application_acls_size() const {
  return application_acls_.size();
}
inline void RegisterApplicationMasterResponseProto::clear_application_acls() {
  application_acls_.Clear();
}
inline const ::hadoop::yarn::ApplicationACLMapProto& RegisterApplicationMasterResponseProto::application_acls(int index) const {
  return application_acls_.Get(index);
}
inline ::hadoop::yarn::ApplicationACLMapProto* RegisterApplicationMasterResponseProto::mutable_application_acls(int index) {
  return application_acls_.Mutable(index);
}
inline ::hadoop::yarn::ApplicationACLMapProto* RegisterApplicationMasterResponseProto::add_application_acls() {
  return application_acls_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationACLMapProto >&
RegisterApplicationMasterResponseProto::application_acls() const {
  return application_acls_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationACLMapProto >*
RegisterApplicationMasterResponseProto::mutable_application_acls() {
  return &application_acls_;
}

// -------------------------------------------------------------------

// FinishApplicationMasterRequestProto

// optional string diagnostics = 1;
inline bool FinishApplicationMasterRequestProto::has_diagnostics() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void FinishApplicationMasterRequestProto::set_has_diagnostics() {
  _has_bits_[0] |= 0x00000001u;
}
inline void FinishApplicationMasterRequestProto::clear_has_diagnostics() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void FinishApplicationMasterRequestProto::clear_diagnostics() {
  if (diagnostics_ != &::google::protobuf::internal::kEmptyString) {
    diagnostics_->clear();
  }
  clear_has_diagnostics();
}
inline const ::std::string& FinishApplicationMasterRequestProto::diagnostics() const {
  return *diagnostics_;
}
inline void FinishApplicationMasterRequestProto::set_diagnostics(const ::std::string& value) {
  set_has_diagnostics();
  if (diagnostics_ == &::google::protobuf::internal::kEmptyString) {
    diagnostics_ = new ::std::string;
  }
  diagnostics_->assign(value);
}
inline void FinishApplicationMasterRequestProto::set_diagnostics(const char* value) {
  set_has_diagnostics();
  if (diagnostics_ == &::google::protobuf::internal::kEmptyString) {
    diagnostics_ = new ::std::string;
  }
  diagnostics_->assign(value);
}
inline void FinishApplicationMasterRequestProto::set_diagnostics(const char* value, size_t size) {
  set_has_diagnostics();
  if (diagnostics_ == &::google::protobuf::internal::kEmptyString) {
    diagnostics_ = new ::std::string;
  }
  diagnostics_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* FinishApplicationMasterRequestProto::mutable_diagnostics() {
  set_has_diagnostics();
  if (diagnostics_ == &::google::protobuf::internal::kEmptyString) {
    diagnostics_ = new ::std::string;
  }
  return diagnostics_;
}
inline ::std::string* FinishApplicationMasterRequestProto::release_diagnostics() {
  clear_has_diagnostics();
  if (diagnostics_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = diagnostics_;
    diagnostics_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void FinishApplicationMasterRequestProto::set_allocated_diagnostics(::std::string* diagnostics) {
  if (diagnostics_ != &::google::protobuf::internal::kEmptyString) {
    delete diagnostics_;
  }
  if (diagnostics) {
    set_has_diagnostics();
    diagnostics_ = diagnostics;
  } else {
    clear_has_diagnostics();
    diagnostics_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional string tracking_url = 2;
inline bool FinishApplicationMasterRequestProto::has_tracking_url() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void FinishApplicationMasterRequestProto::set_has_tracking_url() {
  _has_bits_[0] |= 0x00000002u;
}
inline void FinishApplicationMasterRequestProto::clear_has_tracking_url() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void FinishApplicationMasterRequestProto::clear_tracking_url() {
  if (tracking_url_ != &::google::protobuf::internal::kEmptyString) {
    tracking_url_->clear();
  }
  clear_has_tracking_url();
}
inline const ::std::string& FinishApplicationMasterRequestProto::tracking_url() const {
  return *tracking_url_;
}
inline void FinishApplicationMasterRequestProto::set_tracking_url(const ::std::string& value) {
  set_has_tracking_url();
  if (tracking_url_ == &::google::protobuf::internal::kEmptyString) {
    tracking_url_ = new ::std::string;
  }
  tracking_url_->assign(value);
}
inline void FinishApplicationMasterRequestProto::set_tracking_url(const char* value) {
  set_has_tracking_url();
  if (tracking_url_ == &::google::protobuf::internal::kEmptyString) {
    tracking_url_ = new ::std::string;
  }
  tracking_url_->assign(value);
}
inline void FinishApplicationMasterRequestProto::set_tracking_url(const char* value, size_t size) {
  set_has_tracking_url();
  if (tracking_url_ == &::google::protobuf::internal::kEmptyString) {
    tracking_url_ = new ::std::string;
  }
  tracking_url_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* FinishApplicationMasterRequestProto::mutable_tracking_url() {
  set_has_tracking_url();
  if (tracking_url_ == &::google::protobuf::internal::kEmptyString) {
    tracking_url_ = new ::std::string;
  }
  return tracking_url_;
}
inline ::std::string* FinishApplicationMasterRequestProto::release_tracking_url() {
  clear_has_tracking_url();
  if (tracking_url_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = tracking_url_;
    tracking_url_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void FinishApplicationMasterRequestProto::set_allocated_tracking_url(::std::string* tracking_url) {
  if (tracking_url_ != &::google::protobuf::internal::kEmptyString) {
    delete tracking_url_;
  }
  if (tracking_url) {
    set_has_tracking_url();
    tracking_url_ = tracking_url;
  } else {
    clear_has_tracking_url();
    tracking_url_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 3;
inline bool FinishApplicationMasterRequestProto::has_final_application_status() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void FinishApplicationMasterRequestProto::set_has_final_application_status() {
  _has_bits_[0] |= 0x00000004u;
}
inline void FinishApplicationMasterRequestProto::clear_has_final_application_status() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void FinishApplicationMasterRequestProto::clear_final_application_status() {
  final_application_status_ = 0;
  clear_has_final_application_status();
}
inline ::hadoop::yarn::FinalApplicationStatusProto FinishApplicationMasterRequestProto::final_application_status() const {
  return static_cast< ::hadoop::yarn::FinalApplicationStatusProto >(final_application_status_);
}
inline void FinishApplicationMasterRequestProto::set_final_application_status(::hadoop::yarn::FinalApplicationStatusProto value) {
  assert(::hadoop::yarn::FinalApplicationStatusProto_IsValid(value));
  set_has_final_application_status();
  final_application_status_ = value;
}

// -------------------------------------------------------------------

// FinishApplicationMasterResponseProto

// optional bool isUnregistered = 1 [default = false];
inline bool FinishApplicationMasterResponseProto::has_isunregistered() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void FinishApplicationMasterResponseProto::set_has_isunregistered() {
  _has_bits_[0] |= 0x00000001u;
}
inline void FinishApplicationMasterResponseProto::clear_has_isunregistered() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void FinishApplicationMasterResponseProto::clear_isunregistered() {
  isunregistered_ = false;
  clear_has_isunregistered();
}
inline bool FinishApplicationMasterResponseProto::isunregistered() const {
  return isunregistered_;
}
inline void FinishApplicationMasterResponseProto::set_isunregistered(bool value) {
  set_has_isunregistered();
  isunregistered_ = value;
}

// -------------------------------------------------------------------

// AllocateRequestProto

// repeated .hadoop.yarn.ResourceRequestProto ask = 1;
inline int AllocateRequestProto::ask_size() const {
  return ask_.size();
}
inline void AllocateRequestProto::clear_ask() {
  ask_.Clear();
}
inline const ::hadoop::yarn::ResourceRequestProto& AllocateRequestProto::ask(int index) const {
  return ask_.Get(index);
}
inline ::hadoop::yarn::ResourceRequestProto* AllocateRequestProto::mutable_ask(int index) {
  return ask_.Mutable(index);
}
inline ::hadoop::yarn::ResourceRequestProto* AllocateRequestProto::add_ask() {
  return ask_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ResourceRequestProto >&
AllocateRequestProto::ask() const {
  return ask_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ResourceRequestProto >*
AllocateRequestProto::mutable_ask() {
  return &ask_;
}

// repeated .hadoop.yarn.ContainerIdProto release = 2;
inline int AllocateRequestProto::release_size() const {
  return release_.size();
}
inline void AllocateRequestProto::clear_release() {
  release_.Clear();
}
inline const ::hadoop::yarn::ContainerIdProto& AllocateRequestProto::release(int index) const {
  return release_.Get(index);
}
inline ::hadoop::yarn::ContainerIdProto* AllocateRequestProto::mutable_release(int index) {
  return release_.Mutable(index);
}
inline ::hadoop::yarn::ContainerIdProto* AllocateRequestProto::add_release() {
  return release_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >&
AllocateRequestProto::release() const {
  return release_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >*
AllocateRequestProto::mutable_release() {
  return &release_;
}

// optional .hadoop.yarn.ResourceBlacklistRequestProto blacklist_request = 3;
inline bool AllocateRequestProto::has_blacklist_request() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void AllocateRequestProto::set_has_blacklist_request() {
  _has_bits_[0] |= 0x00000004u;
}
inline void AllocateRequestProto::clear_has_blacklist_request() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void AllocateRequestProto::clear_blacklist_request() {
  if (blacklist_request_ != NULL) blacklist_request_->::hadoop::yarn::ResourceBlacklistRequestProto::Clear();
  clear_has_blacklist_request();
}
inline const ::hadoop::yarn::ResourceBlacklistRequestProto& AllocateRequestProto::blacklist_request() const {
  return blacklist_request_ != NULL ? *blacklist_request_ : *default_instance_->blacklist_request_;
}
inline ::hadoop::yarn::ResourceBlacklistRequestProto* AllocateRequestProto::mutable_blacklist_request() {
  set_has_blacklist_request();
  if (blacklist_request_ == NULL) blacklist_request_ = new ::hadoop::yarn::ResourceBlacklistRequestProto;
  return blacklist_request_;
}
inline ::hadoop::yarn::ResourceBlacklistRequestProto* AllocateRequestProto::release_blacklist_request() {
  clear_has_blacklist_request();
  ::hadoop::yarn::ResourceBlacklistRequestProto* temp = blacklist_request_;
  blacklist_request_ = NULL;
  return temp;
}
inline void AllocateRequestProto::set_allocated_blacklist_request(::hadoop::yarn::ResourceBlacklistRequestProto* blacklist_request) {
  delete blacklist_request_;
  blacklist_request_ = blacklist_request;
  if (blacklist_request) {
    set_has_blacklist_request();
  } else {
    clear_has_blacklist_request();
  }
}

// optional int32 response_id = 4;
inline bool AllocateRequestProto::has_response_id() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void AllocateRequestProto::set_has_response_id() {
  _has_bits_[0] |= 0x00000008u;
}
inline void AllocateRequestProto::clear_has_response_id() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void AllocateRequestProto::clear_response_id() {
  response_id_ = 0;
  clear_has_response_id();
}
inline ::google::protobuf::int32 AllocateRequestProto::response_id() const {
  return response_id_;
}
inline void AllocateRequestProto::set_response_id(::google::protobuf::int32 value) {
  set_has_response_id();
  response_id_ = value;
}

// optional float progress = 5;
inline bool AllocateRequestProto::has_progress() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void AllocateRequestProto::set_has_progress() {
  _has_bits_[0] |= 0x00000010u;
}
inline void AllocateRequestProto::clear_has_progress() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void AllocateRequestProto::clear_progress() {
  progress_ = 0;
  clear_has_progress();
}
inline float AllocateRequestProto::progress() const {
  return progress_;
}
inline void AllocateRequestProto::set_progress(float value) {
  set_has_progress();
  progress_ = value;
}

// -------------------------------------------------------------------

// NMTokenProto

// optional .hadoop.yarn.NodeIdProto nodeId = 1;
inline bool NMTokenProto::has_nodeid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void NMTokenProto::set_has_nodeid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void NMTokenProto::clear_has_nodeid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void NMTokenProto::clear_nodeid() {
  if (nodeid_ != NULL) nodeid_->::hadoop::yarn::NodeIdProto::Clear();
  clear_has_nodeid();
}
inline const ::hadoop::yarn::NodeIdProto& NMTokenProto::nodeid() const {
  return nodeid_ != NULL ? *nodeid_ : *default_instance_->nodeid_;
}
inline ::hadoop::yarn::NodeIdProto* NMTokenProto::mutable_nodeid() {
  set_has_nodeid();
  if (nodeid_ == NULL) nodeid_ = new ::hadoop::yarn::NodeIdProto;
  return nodeid_;
}
inline ::hadoop::yarn::NodeIdProto* NMTokenProto::release_nodeid() {
  clear_has_nodeid();
  ::hadoop::yarn::NodeIdProto* temp = nodeid_;
  nodeid_ = NULL;
  return temp;
}
inline void NMTokenProto::set_allocated_nodeid(::hadoop::yarn::NodeIdProto* nodeid) {
  delete nodeid_;
  nodeid_ = nodeid;
  if (nodeid) {
    set_has_nodeid();
  } else {
    clear_has_nodeid();
  }
}

// optional .hadoop.common.TokenProto token = 2;
inline bool NMTokenProto::has_token() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void NMTokenProto::set_has_token() {
  _has_bits_[0] |= 0x00000002u;
}
inline void NMTokenProto::clear_has_token() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void NMTokenProto::clear_token() {
  if (token_ != NULL) token_->::hadoop::common::TokenProto::Clear();
  clear_has_token();
}
inline const ::hadoop::common::TokenProto& NMTokenProto::token() const {
  return token_ != NULL ? *token_ : *default_instance_->token_;
}
inline ::hadoop::common::TokenProto* NMTokenProto::mutable_token() {
  set_has_token();
  if (token_ == NULL) token_ = new ::hadoop::common::TokenProto;
  return token_;
}
inline ::hadoop::common::TokenProto* NMTokenProto::release_token() {
  clear_has_token();
  ::hadoop::common::TokenProto* temp = token_;
  token_ = NULL;
  return temp;
}
inline void NMTokenProto::set_allocated_token(::hadoop::common::TokenProto* token) {
  delete token_;
  token_ = token;
  if (token) {
    set_has_token();
  } else {
    clear_has_token();
  }
}

// -------------------------------------------------------------------

// AllocateResponseProto

// optional .hadoop.yarn.AMCommandProto a_m_command = 1;
inline bool AllocateResponseProto::has_a_m_command() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void AllocateResponseProto::set_has_a_m_command() {
  _has_bits_[0] |= 0x00000001u;
}
inline void AllocateResponseProto::clear_has_a_m_command() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void AllocateResponseProto::clear_a_m_command() {
  a_m_command_ = 1;
  clear_has_a_m_command();
}
inline ::hadoop::yarn::AMCommandProto AllocateResponseProto::a_m_command() const {
  return static_cast< ::hadoop::yarn::AMCommandProto >(a_m_command_);
}
inline void AllocateResponseProto::set_a_m_command(::hadoop::yarn::AMCommandProto value) {
  assert(::hadoop::yarn::AMCommandProto_IsValid(value));
  set_has_a_m_command();
  a_m_command_ = value;
}

// optional int32 response_id = 2;
inline bool AllocateResponseProto::has_response_id() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void AllocateResponseProto::set_has_response_id() {
  _has_bits_[0] |= 0x00000002u;
}
inline void AllocateResponseProto::clear_has_response_id() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void AllocateResponseProto::clear_response_id() {
  response_id_ = 0;
  clear_has_response_id();
}
inline ::google::protobuf::int32 AllocateResponseProto::response_id() const {
  return response_id_;
}
inline void AllocateResponseProto::set_response_id(::google::protobuf::int32 value) {
  set_has_response_id();
  response_id_ = value;
}

// repeated .hadoop.yarn.ContainerProto allocated_containers = 3;
inline int AllocateResponseProto::allocated_containers_size() const {
  return allocated_containers_.size();
}
inline void AllocateResponseProto::clear_allocated_containers() {
  allocated_containers_.Clear();
}
inline const ::hadoop::yarn::ContainerProto& AllocateResponseProto::allocated_containers(int index) const {
  return allocated_containers_.Get(index);
}
inline ::hadoop::yarn::ContainerProto* AllocateResponseProto::mutable_allocated_containers(int index) {
  return allocated_containers_.Mutable(index);
}
inline ::hadoop::yarn::ContainerProto* AllocateResponseProto::add_allocated_containers() {
  return allocated_containers_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerProto >&
AllocateResponseProto::allocated_containers() const {
  return allocated_containers_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerProto >*
AllocateResponseProto::mutable_allocated_containers() {
  return &allocated_containers_;
}

// repeated .hadoop.yarn.ContainerStatusProto completed_container_statuses = 4;
inline int AllocateResponseProto::completed_container_statuses_size() const {
  return completed_container_statuses_.size();
}
inline void AllocateResponseProto::clear_completed_container_statuses() {
  completed_container_statuses_.Clear();
}
inline const ::hadoop::yarn::ContainerStatusProto& AllocateResponseProto::completed_container_statuses(int index) const {
  return completed_container_statuses_.Get(index);
}
inline ::hadoop::yarn::ContainerStatusProto* AllocateResponseProto::mutable_completed_container_statuses(int index) {
  return completed_container_statuses_.Mutable(index);
}
inline ::hadoop::yarn::ContainerStatusProto* AllocateResponseProto::add_completed_container_statuses() {
  return completed_container_statuses_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerStatusProto >&
AllocateResponseProto::completed_container_statuses() const {
  return completed_container_statuses_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerStatusProto >*
AllocateResponseProto::mutable_completed_container_statuses() {
  return &completed_container_statuses_;
}

// optional .hadoop.yarn.ResourceProto limit = 5;
inline bool AllocateResponseProto::has_limit() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void AllocateResponseProto::set_has_limit() {
  _has_bits_[0] |= 0x00000010u;
}
inline void AllocateResponseProto::clear_has_limit() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void AllocateResponseProto::clear_limit() {
  if (limit_ != NULL) limit_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_limit();
}
inline const ::hadoop::yarn::ResourceProto& AllocateResponseProto::limit() const {
  return limit_ != NULL ? *limit_ : *default_instance_->limit_;
}
inline ::hadoop::yarn::ResourceProto* AllocateResponseProto::mutable_limit() {
  set_has_limit();
  if (limit_ == NULL) limit_ = new ::hadoop::yarn::ResourceProto;
  return limit_;
}
inline ::hadoop::yarn::ResourceProto* AllocateResponseProto::release_limit() {
  clear_has_limit();
  ::hadoop::yarn::ResourceProto* temp = limit_;
  limit_ = NULL;
  return temp;
}
inline void AllocateResponseProto::set_allocated_limit(::hadoop::yarn::ResourceProto* limit) {
  delete limit_;
  limit_ = limit;
  if (limit) {
    set_has_limit();
  } else {
    clear_has_limit();
  }
}

// repeated .hadoop.yarn.NodeReportProto updated_nodes = 6;
inline int AllocateResponseProto::updated_nodes_size() const {
  return updated_nodes_.size();
}
inline void AllocateResponseProto::clear_updated_nodes() {
  updated_nodes_.Clear();
}
inline const ::hadoop::yarn::NodeReportProto& AllocateResponseProto::updated_nodes(int index) const {
  return updated_nodes_.Get(index);
}
inline ::hadoop::yarn::NodeReportProto* AllocateResponseProto::mutable_updated_nodes(int index) {
  return updated_nodes_.Mutable(index);
}
inline ::hadoop::yarn::NodeReportProto* AllocateResponseProto::add_updated_nodes() {
  return updated_nodes_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NodeReportProto >&
AllocateResponseProto::updated_nodes() const {
  return updated_nodes_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NodeReportProto >*
AllocateResponseProto::mutable_updated_nodes() {
  return &updated_nodes_;
}

// optional int32 num_cluster_nodes = 7;
inline bool AllocateResponseProto::has_num_cluster_nodes() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
inline void AllocateResponseProto::set_has_num_cluster_nodes() {
  _has_bits_[0] |= 0x00000040u;
}
inline void AllocateResponseProto::clear_has_num_cluster_nodes() {
  _has_bits_[0] &= ~0x00000040u;
}
inline void AllocateResponseProto::clear_num_cluster_nodes() {
  num_cluster_nodes_ = 0;
  clear_has_num_cluster_nodes();
}
inline ::google::protobuf::int32 AllocateResponseProto::num_cluster_nodes() const {
  return num_cluster_nodes_;
}
inline void AllocateResponseProto::set_num_cluster_nodes(::google::protobuf::int32 value) {
  set_has_num_cluster_nodes();
  num_cluster_nodes_ = value;
}

// optional .hadoop.yarn.PreemptionMessageProto preempt = 8;
inline bool AllocateResponseProto::has_preempt() const {
  return (_has_bits_[0] & 0x00000080u) != 0;
}
inline void AllocateResponseProto::set_has_preempt() {
  _has_bits_[0] |= 0x00000080u;
}
inline void AllocateResponseProto::clear_has_preempt() {
  _has_bits_[0] &= ~0x00000080u;
}
inline void AllocateResponseProto::clear_preempt() {
  if (preempt_ != NULL) preempt_->::hadoop::yarn::PreemptionMessageProto::Clear();
  clear_has_preempt();
}
inline const ::hadoop::yarn::PreemptionMessageProto& AllocateResponseProto::preempt() const {
  return preempt_ != NULL ? *preempt_ : *default_instance_->preempt_;
}
inline ::hadoop::yarn::PreemptionMessageProto* AllocateResponseProto::mutable_preempt() {
  set_has_preempt();
  if (preempt_ == NULL) preempt_ = new ::hadoop::yarn::PreemptionMessageProto;
  return preempt_;
}
inline ::hadoop::yarn::PreemptionMessageProto* AllocateResponseProto::release_preempt() {
  clear_has_preempt();
  ::hadoop::yarn::PreemptionMessageProto* temp = preempt_;
  preempt_ = NULL;
  return temp;
}
inline void AllocateResponseProto::set_allocated_preempt(::hadoop::yarn::PreemptionMessageProto* preempt) {
  delete preempt_;
  preempt_ = preempt;
  if (preempt) {
    set_has_preempt();
  } else {
    clear_has_preempt();
  }
}

// repeated .hadoop.yarn.NMTokenProto nm_tokens = 9;
inline int AllocateResponseProto::nm_tokens_size() const {
  return nm_tokens_.size();
}
inline void AllocateResponseProto::clear_nm_tokens() {
  nm_tokens_.Clear();
}
inline const ::hadoop::yarn::NMTokenProto& AllocateResponseProto::nm_tokens(int index) const {
  return nm_tokens_.Get(index);
}
inline ::hadoop::yarn::NMTokenProto* AllocateResponseProto::mutable_nm_tokens(int index) {
  return nm_tokens_.Mutable(index);
}
inline ::hadoop::yarn::NMTokenProto* AllocateResponseProto::add_nm_tokens() {
  return nm_tokens_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NMTokenProto >&
AllocateResponseProto::nm_tokens() const {
  return nm_tokens_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NMTokenProto >*
AllocateResponseProto::mutable_nm_tokens() {
  return &nm_tokens_;
}

// -------------------------------------------------------------------

// GetNewApplicationRequestProto

// -------------------------------------------------------------------

// GetNewApplicationResponseProto

// optional .hadoop.yarn.ApplicationIdProto application_id = 1;
inline bool GetNewApplicationResponseProto::has_application_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void GetNewApplicationResponseProto::set_has_application_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void GetNewApplicationResponseProto::clear_has_application_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void GetNewApplicationResponseProto::clear_application_id() {
  if (application_id_ != NULL) application_id_->::hadoop::yarn::ApplicationIdProto::Clear();
  clear_has_application_id();
}
inline const ::hadoop::yarn::ApplicationIdProto& GetNewApplicationResponseProto::application_id() const {
  return application_id_ != NULL ? *application_id_ : *default_instance_->application_id_;
}
inline ::hadoop::yarn::ApplicationIdProto* GetNewApplicationResponseProto::mutable_application_id() {
  set_has_application_id();
  if (application_id_ == NULL) application_id_ = new ::hadoop::yarn::ApplicationIdProto;
  return application_id_;
}
inline ::hadoop::yarn::ApplicationIdProto* GetNewApplicationResponseProto::release_application_id() {
  clear_has_application_id();
  ::hadoop::yarn::ApplicationIdProto* temp = application_id_;
  application_id_ = NULL;
  return temp;
}
inline void GetNewApplicationResponseProto::set_allocated_application_id(::hadoop::yarn::ApplicationIdProto* application_id) {
  delete application_id_;
  application_id_ = application_id;
  if (application_id) {
    set_has_application_id();
  } else {
    clear_has_application_id();
  }
}

// optional .hadoop.yarn.ResourceProto maximumCapability = 2;
inline bool GetNewApplicationResponseProto::has_maximumcapability() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void GetNewApplicationResponseProto::set_has_maximumcapability() {
  _has_bits_[0] |= 0x00000002u;
}
inline void GetNewApplicationResponseProto::clear_has_maximumcapability() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void GetNewApplicationResponseProto::clear_maximumcapability() {
  if (maximumcapability_ != NULL) maximumcapability_->::hadoop::yarn::ResourceProto::Clear();
  clear_has_maximumcapability();
}
inline const ::hadoop::yarn::ResourceProto& GetNewApplicationResponseProto::maximumcapability() const {
  return maximumcapability_ != NULL ? *maximumcapability_ : *default_instance_->maximumcapability_;
}
inline ::hadoop::yarn::ResourceProto* GetNewApplicationResponseProto::mutable_maximumcapability() {
  set_has_maximumcapability();
  if (maximumcapability_ == NULL) maximumcapability_ = new ::hadoop::yarn::ResourceProto;
  return maximumcapability_;
}
inline ::hadoop::yarn::ResourceProto* GetNewApplicationResponseProto::release_maximumcapability() {
  clear_has_maximumcapability();
  ::hadoop::yarn::ResourceProto* temp = maximumcapability_;
  maximumcapability_ = NULL;
  return temp;
}
inline void GetNewApplicationResponseProto::set_allocated_maximumcapability(::hadoop::yarn::ResourceProto* maximumcapability) {
  delete maximumcapability_;
  maximumcapability_ = maximumcapability;
  if (maximumcapability) {
    set_has_maximumcapability();
  } else {
    clear_has_maximumcapability();
  }
}

// -------------------------------------------------------------------

// GetApplicationReportRequestProto

// optional .hadoop.yarn.ApplicationIdProto application_id = 1;
inline bool GetApplicationReportRequestProto::has_application_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void GetApplicationReportRequestProto::set_has_application_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void GetApplicationReportRequestProto::clear_has_application_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void GetApplicationReportRequestProto::clear_application_id() {
  if (application_id_ != NULL) application_id_->::hadoop::yarn::ApplicationIdProto::Clear();
  clear_has_application_id();
}
inline const ::hadoop::yarn::ApplicationIdProto& GetApplicationReportRequestProto::application_id() const {
  return application_id_ != NULL ? *application_id_ : *default_instance_->application_id_;
}
inline ::hadoop::yarn::ApplicationIdProto* GetApplicationReportRequestProto::mutable_application_id() {
  set_has_application_id();
  if (application_id_ == NULL) application_id_ = new ::hadoop::yarn::ApplicationIdProto;
  return application_id_;
}
inline ::hadoop::yarn::ApplicationIdProto* GetApplicationReportRequestProto::release_application_id() {
  clear_has_application_id();
  ::hadoop::yarn::ApplicationIdProto* temp = application_id_;
  application_id_ = NULL;
  return temp;
}
inline void GetApplicationReportRequestProto::set_allocated_application_id(::hadoop::yarn::ApplicationIdProto* application_id) {
  delete application_id_;
  application_id_ = application_id;
  if (application_id) {
    set_has_application_id();
  } else {
    clear_has_application_id();
  }
}

// -------------------------------------------------------------------

// GetApplicationReportResponseProto

// optional .hadoop.yarn.ApplicationReportProto application_report = 1;
inline bool GetApplicationReportResponseProto::has_application_report() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void GetApplicationReportResponseProto::set_has_application_report() {
  _has_bits_[0] |= 0x00000001u;
}
inline void GetApplicationReportResponseProto::clear_has_application_report() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void GetApplicationReportResponseProto::clear_application_report() {
  if (application_report_ != NULL) application_report_->::hadoop::yarn::ApplicationReportProto::Clear();
  clear_has_application_report();
}
inline const ::hadoop::yarn::ApplicationReportProto& GetApplicationReportResponseProto::application_report() const {
  return application_report_ != NULL ? *application_report_ : *default_instance_->application_report_;
}
inline ::hadoop::yarn::ApplicationReportProto* GetApplicationReportResponseProto::mutable_application_report() {
  set_has_application_report();
  if (application_report_ == NULL) application_report_ = new ::hadoop::yarn::ApplicationReportProto;
  return application_report_;
}
inline ::hadoop::yarn::ApplicationReportProto* GetApplicationReportResponseProto::release_application_report() {
  clear_has_application_report();
  ::hadoop::yarn::ApplicationReportProto* temp = application_report_;
  application_report_ = NULL;
  return temp;
}
inline void GetApplicationReportResponseProto::set_allocated_application_report(::hadoop::yarn::ApplicationReportProto* application_report) {
  delete application_report_;
  application_report_ = application_report;
  if (application_report) {
    set_has_application_report();
  } else {
    clear_has_application_report();
  }
}

// -------------------------------------------------------------------

// SubmitApplicationRequestProto

// optional .hadoop.yarn.ApplicationSubmissionContextProto application_submission_context = 1;
inline bool SubmitApplicationRequestProto::has_application_submission_context() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void SubmitApplicationRequestProto::set_has_application_submission_context() {
  _has_bits_[0] |= 0x00000001u;
}
inline void SubmitApplicationRequestProto::clear_has_application_submission_context() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void SubmitApplicationRequestProto::clear_application_submission_context() {
  if (application_submission_context_ != NULL) application_submission_context_->::hadoop::yarn::ApplicationSubmissionContextProto::Clear();
  clear_has_application_submission_context();
}
inline const ::hadoop::yarn::ApplicationSubmissionContextProto& SubmitApplicationRequestProto::application_submission_context() const {
  return application_submission_context_ != NULL ? *application_submission_context_ : *default_instance_->application_submission_context_;
}
inline ::hadoop::yarn::ApplicationSubmissionContextProto* SubmitApplicationRequestProto::mutable_application_submission_context() {
  set_has_application_submission_context();
  if (application_submission_context_ == NULL) application_submission_context_ = new ::hadoop::yarn::ApplicationSubmissionContextProto;
  return application_submission_context_;
}
inline ::hadoop::yarn::ApplicationSubmissionContextProto* SubmitApplicationRequestProto::release_application_submission_context() {
  clear_has_application_submission_context();
  ::hadoop::yarn::ApplicationSubmissionContextProto* temp = application_submission_context_;
  application_submission_context_ = NULL;
  return temp;
}
inline void SubmitApplicationRequestProto::set_allocated_application_submission_context(::hadoop::yarn::ApplicationSubmissionContextProto* application_submission_context) {
  delete application_submission_context_;
  application_submission_context_ = application_submission_context;
  if (application_submission_context) {
    set_has_application_submission_context();
  } else {
    clear_has_application_submission_context();
  }
}

// -------------------------------------------------------------------

// SubmitApplicationResponseProto

// -------------------------------------------------------------------

// KillApplicationRequestProto

// optional .hadoop.yarn.ApplicationIdProto application_id = 1;
inline bool KillApplicationRequestProto::has_application_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void KillApplicationRequestProto::set_has_application_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void KillApplicationRequestProto::clear_has_application_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void KillApplicationRequestProto::clear_application_id() {
  if (application_id_ != NULL) application_id_->::hadoop::yarn::ApplicationIdProto::Clear();
  clear_has_application_id();
}
inline const ::hadoop::yarn::ApplicationIdProto& KillApplicationRequestProto::application_id() const {
  return application_id_ != NULL ? *application_id_ : *default_instance_->application_id_;
}
inline ::hadoop::yarn::ApplicationIdProto* KillApplicationRequestProto::mutable_application_id() {
  set_has_application_id();
  if (application_id_ == NULL) application_id_ = new ::hadoop::yarn::ApplicationIdProto;
  return application_id_;
}
inline ::hadoop::yarn::ApplicationIdProto* KillApplicationRequestProto::release_application_id() {
  clear_has_application_id();
  ::hadoop::yarn::ApplicationIdProto* temp = application_id_;
  application_id_ = NULL;
  return temp;
}
inline void KillApplicationRequestProto::set_allocated_application_id(::hadoop::yarn::ApplicationIdProto* application_id) {
  delete application_id_;
  application_id_ = application_id;
  if (application_id) {
    set_has_application_id();
  } else {
    clear_has_application_id();
  }
}

// -------------------------------------------------------------------

// KillApplicationResponseProto

// -------------------------------------------------------------------

// GetClusterMetricsRequestProto

// -------------------------------------------------------------------

// GetClusterMetricsResponseProto

// optional .hadoop.yarn.YarnClusterMetricsProto cluster_metrics = 1;
inline bool GetClusterMetricsResponseProto::has_cluster_metrics() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void GetClusterMetricsResponseProto::set_has_cluster_metrics() {
  _has_bits_[0] |= 0x00000001u;
}
inline void GetClusterMetricsResponseProto::clear_has_cluster_metrics() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void GetClusterMetricsResponseProto::clear_cluster_metrics() {
  if (cluster_metrics_ != NULL) cluster_metrics_->::hadoop::yarn::YarnClusterMetricsProto::Clear();
  clear_has_cluster_metrics();
}
inline const ::hadoop::yarn::YarnClusterMetricsProto& GetClusterMetricsResponseProto::cluster_metrics() const {
  return cluster_metrics_ != NULL ? *cluster_metrics_ : *default_instance_->cluster_metrics_;
}
inline ::hadoop::yarn::YarnClusterMetricsProto* GetClusterMetricsResponseProto::mutable_cluster_metrics() {
  set_has_cluster_metrics();
  if (cluster_metrics_ == NULL) cluster_metrics_ = new ::hadoop::yarn::YarnClusterMetricsProto;
  return cluster_metrics_;
}
inline ::hadoop::yarn::YarnClusterMetricsProto* GetClusterMetricsResponseProto::release_cluster_metrics() {
  clear_has_cluster_metrics();
  ::hadoop::yarn::YarnClusterMetricsProto* temp = cluster_metrics_;
  cluster_metrics_ = NULL;
  return temp;
}
inline void GetClusterMetricsResponseProto::set_allocated_cluster_metrics(::hadoop::yarn::YarnClusterMetricsProto* cluster_metrics) {
  delete cluster_metrics_;
  cluster_metrics_ = cluster_metrics;
  if (cluster_metrics) {
    set_has_cluster_metrics();
  } else {
    clear_has_cluster_metrics();
  }
}

// -------------------------------------------------------------------

// GetApplicationsRequestProto

// repeated string application_types = 1;
inline int GetApplicationsRequestProto::application_types_size() const {
  return application_types_.size();
}
inline void GetApplicationsRequestProto::clear_application_types() {
  application_types_.Clear();
}
inline const ::std::string& GetApplicationsRequestProto::application_types(int index) const {
  return application_types_.Get(index);
}
inline ::std::string* GetApplicationsRequestProto::mutable_application_types(int index) {
  return application_types_.Mutable(index);
}
inline void GetApplicationsRequestProto::set_application_types(int index, const ::std::string& value) {
  application_types_.Mutable(index)->assign(value);
}
inline void GetApplicationsRequestProto::set_application_types(int index, const char* value) {
  application_types_.Mutable(index)->assign(value);
}
inline void GetApplicationsRequestProto::set_application_types(int index, const char* value, size_t size) {
  application_types_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
}
inline ::std::string* GetApplicationsRequestProto::add_application_types() {
  return application_types_.Add();
}
inline void GetApplicationsRequestProto::add_application_types(const ::std::string& value) {
  application_types_.Add()->assign(value);
}
inline void GetApplicationsRequestProto::add_application_types(const char* value) {
  application_types_.Add()->assign(value);
}
inline void GetApplicationsRequestProto::add_application_types(const char* value, size_t size) {
  application_types_.Add()->assign(reinterpret_cast<const char*>(value), size);
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
GetApplicationsRequestProto::application_types() const {
  return application_types_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
GetApplicationsRequestProto::mutable_application_types() {
  return &application_types_;
}

// repeated .hadoop.yarn.YarnApplicationStateProto application_states = 2;
inline int GetApplicationsRequestProto::application_states_size() const {
  return application_states_.size();
}
inline void GetApplicationsRequestProto::clear_application_states() {
  application_states_.Clear();
}
inline ::hadoop::yarn::YarnApplicationStateProto GetApplicationsRequestProto::application_states(int index) const {
  return static_cast< ::hadoop::yarn::YarnApplicationStateProto >(application_states_.Get(index));
}
inline void GetApplicationsRequestProto::set_application_states(int index, ::hadoop::yarn::YarnApplicationStateProto value) {
  assert(::hadoop::yarn::YarnApplicationStateProto_IsValid(value));
  application_states_.Set(index, value);
}
inline void GetApplicationsRequestProto::add_application_states(::hadoop::yarn::YarnApplicationStateProto value) {
  assert(::hadoop::yarn::YarnApplicationStateProto_IsValid(value));
  application_states_.Add(value);
}
inline const ::google::protobuf::RepeatedField<int>&
GetApplicationsRequestProto::application_states() const {
  return application_states_;
}
inline ::google::protobuf::RepeatedField<int>*
GetApplicationsRequestProto::mutable_application_states() {
  return &application_states_;
}

// -------------------------------------------------------------------

// GetApplicationsResponseProto

// repeated .hadoop.yarn.ApplicationReportProto applications = 1;
inline int GetApplicationsResponseProto::applications_size() const {
  return applications_.size();
}
inline void GetApplicationsResponseProto::clear_applications() {
  applications_.Clear();
}
inline const ::hadoop::yarn::ApplicationReportProto& GetApplicationsResponseProto::applications(int index) const {
  return applications_.Get(index);
}
inline ::hadoop::yarn::ApplicationReportProto* GetApplicationsResponseProto::mutable_applications(int index) {
  return applications_.Mutable(index);
}
inline ::hadoop::yarn::ApplicationReportProto* GetApplicationsResponseProto::add_applications() {
  return applications_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationReportProto >&
GetApplicationsResponseProto::applications() const {
  return applications_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ApplicationReportProto >*
GetApplicationsResponseProto::mutable_applications() {
  return &applications_;
}

// -------------------------------------------------------------------

// GetClusterNodesRequestProto

// repeated .hadoop.yarn.NodeStateProto nodeStates = 1;
inline int GetClusterNodesRequestProto::nodestates_size() const {
  return nodestates_.size();
}
inline void GetClusterNodesRequestProto::clear_nodestates() {
  nodestates_.Clear();
}
inline ::hadoop::yarn::NodeStateProto GetClusterNodesRequestProto::nodestates(int index) const {
  return static_cast< ::hadoop::yarn::NodeStateProto >(nodestates_.Get(index));
}
inline void GetClusterNodesRequestProto::set_nodestates(int index, ::hadoop::yarn::NodeStateProto value) {
  assert(::hadoop::yarn::NodeStateProto_IsValid(value));
  nodestates_.Set(index, value);
}
inline void GetClusterNodesRequestProto::add_nodestates(::hadoop::yarn::NodeStateProto value) {
  assert(::hadoop::yarn::NodeStateProto_IsValid(value));
  nodestates_.Add(value);
}
inline const ::google::protobuf::RepeatedField<int>&
GetClusterNodesRequestProto::nodestates() const {
  return nodestates_;
}
inline ::google::protobuf::RepeatedField<int>*
GetClusterNodesRequestProto::mutable_nodestates() {
  return &nodestates_;
}

// -------------------------------------------------------------------

// GetClusterNodesResponseProto

// repeated .hadoop.yarn.NodeReportProto nodeReports = 1;
inline int GetClusterNodesResponseProto::nodereports_size() const {
  return nodereports_.size();
}
inline void GetClusterNodesResponseProto::clear_nodereports() {
  nodereports_.Clear();
}
inline const ::hadoop::yarn::NodeReportProto& GetClusterNodesResponseProto::nodereports(int index) const {
  return nodereports_.Get(index);
}
inline ::hadoop::yarn::NodeReportProto* GetClusterNodesResponseProto::mutable_nodereports(int index) {
  return nodereports_.Mutable(index);
}
inline ::hadoop::yarn::NodeReportProto* GetClusterNodesResponseProto::add_nodereports() {
  return nodereports_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NodeReportProto >&
GetClusterNodesResponseProto::nodereports() const {
  return nodereports_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::NodeReportProto >*
GetClusterNodesResponseProto::mutable_nodereports() {
  return &nodereports_;
}

// -------------------------------------------------------------------

// GetQueueInfoRequestProto

// optional string queueName = 1;
inline bool GetQueueInfoRequestProto::has_queuename() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void GetQueueInfoRequestProto::set_has_queuename() {
  _has_bits_[0] |= 0x00000001u;
}
inline void GetQueueInfoRequestProto::clear_has_queuename() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void GetQueueInfoRequestProto::clear_queuename() {
  if (queuename_ != &::google::protobuf::internal::kEmptyString) {
    queuename_->clear();
  }
  clear_has_queuename();
}
inline const ::std::string& GetQueueInfoRequestProto::queuename() const {
  return *queuename_;
}
inline void GetQueueInfoRequestProto::set_queuename(const ::std::string& value) {
  set_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    queuename_ = new ::std::string;
  }
  queuename_->assign(value);
}
inline void GetQueueInfoRequestProto::set_queuename(const char* value) {
  set_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    queuename_ = new ::std::string;
  }
  queuename_->assign(value);
}
inline void GetQueueInfoRequestProto::set_queuename(const char* value, size_t size) {
  set_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    queuename_ = new ::std::string;
  }
  queuename_->assign(reinterpret_cast<const char*>(value), size);
}
inline ::std::string* GetQueueInfoRequestProto::mutable_queuename() {
  set_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    queuename_ = new ::std::string;
  }
  return queuename_;
}
inline ::std::string* GetQueueInfoRequestProto::release_queuename() {
  clear_has_queuename();
  if (queuename_ == &::google::protobuf::internal::kEmptyString) {
    return NULL;
  } else {
    ::std::string* temp = queuename_;
    queuename_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
    return temp;
  }
}
inline void GetQueueInfoRequestProto::set_allocated_queuename(::std::string* queuename) {
  if (queuename_ != &::google::protobuf::internal::kEmptyString) {
    delete queuename_;
  }
  if (queuename) {
    set_has_queuename();
    queuename_ = queuename;
  } else {
    clear_has_queuename();
    queuename_ = const_cast< ::std::string*>(&::google::protobuf::internal::kEmptyString);
  }
}

// optional bool includeApplications = 2;
inline bool GetQueueInfoRequestProto::has_includeapplications() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void GetQueueInfoRequestProto::set_has_includeapplications() {
  _has_bits_[0] |= 0x00000002u;
}
inline void GetQueueInfoRequestProto::clear_has_includeapplications() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void GetQueueInfoRequestProto::clear_includeapplications() {
  includeapplications_ = false;
  clear_has_includeapplications();
}
inline bool GetQueueInfoRequestProto::includeapplications() const {
  return includeapplications_;
}
inline void GetQueueInfoRequestProto::set_includeapplications(bool value) {
  set_has_includeapplications();
  includeapplications_ = value;
}

// optional bool includeChildQueues = 3;
inline bool GetQueueInfoRequestProto::has_includechildqueues() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void GetQueueInfoRequestProto::set_has_includechildqueues() {
  _has_bits_[0] |= 0x00000004u;
}
inline void GetQueueInfoRequestProto::clear_has_includechildqueues() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void GetQueueInfoRequestProto::clear_includechildqueues() {
  includechildqueues_ = false;
  clear_has_includechildqueues();
}
inline bool GetQueueInfoRequestProto::includechildqueues() const {
  return includechildqueues_;
}
inline void GetQueueInfoRequestProto::set_includechildqueues(bool value) {
  set_has_includechildqueues();
  includechildqueues_ = value;
}

// optional bool recursive = 4;
inline bool GetQueueInfoRequestProto::has_recursive() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void GetQueueInfoRequestProto::set_has_recursive() {
  _has_bits_[0] |= 0x00000008u;
}
inline void GetQueueInfoRequestProto::clear_has_recursive() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void GetQueueInfoRequestProto::clear_recursive() {
  recursive_ = false;
  clear_has_recursive();
}
inline bool GetQueueInfoRequestProto::recursive() const {
  return recursive_;
}
inline void GetQueueInfoRequestProto::set_recursive(bool value) {
  set_has_recursive();
  recursive_ = value;
}

// -------------------------------------------------------------------

// GetQueueInfoResponseProto

// optional .hadoop.yarn.QueueInfoProto queueInfo = 1;
inline bool GetQueueInfoResponseProto::has_queueinfo() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void GetQueueInfoResponseProto::set_has_queueinfo() {
  _has_bits_[0] |= 0x00000001u;
}
inline void GetQueueInfoResponseProto::clear_has_queueinfo() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void GetQueueInfoResponseProto::clear_queueinfo() {
  if (queueinfo_ != NULL) queueinfo_->::hadoop::yarn::QueueInfoProto::Clear();
  clear_has_queueinfo();
}
inline const ::hadoop::yarn::QueueInfoProto& GetQueueInfoResponseProto::queueinfo() const {
  return queueinfo_ != NULL ? *queueinfo_ : *default_instance_->queueinfo_;
}
inline ::hadoop::yarn::QueueInfoProto* GetQueueInfoResponseProto::mutable_queueinfo() {
  set_has_queueinfo();
  if (queueinfo_ == NULL) queueinfo_ = new ::hadoop::yarn::QueueInfoProto;
  return queueinfo_;
}
inline ::hadoop::yarn::QueueInfoProto* GetQueueInfoResponseProto::release_queueinfo() {
  clear_has_queueinfo();
  ::hadoop::yarn::QueueInfoProto* temp = queueinfo_;
  queueinfo_ = NULL;
  return temp;
}
inline void GetQueueInfoResponseProto::set_allocated_queueinfo(::hadoop::yarn::QueueInfoProto* queueinfo) {
  delete queueinfo_;
  queueinfo_ = queueinfo;
  if (queueinfo) {
    set_has_queueinfo();
  } else {
    clear_has_queueinfo();
  }
}

// -------------------------------------------------------------------

// GetQueueUserAclsInfoRequestProto

// -------------------------------------------------------------------

// GetQueueUserAclsInfoResponseProto

// repeated .hadoop.yarn.QueueUserACLInfoProto queueUserAcls = 1;
inline int GetQueueUserAclsInfoResponseProto::queueuseracls_size() const {
  return queueuseracls_.size();
}
inline void GetQueueUserAclsInfoResponseProto::clear_queueuseracls() {
  queueuseracls_.Clear();
}
inline const ::hadoop::yarn::QueueUserACLInfoProto& GetQueueUserAclsInfoResponseProto::queueuseracls(int index) const {
  return queueuseracls_.Get(index);
}
inline ::hadoop::yarn::QueueUserACLInfoProto* GetQueueUserAclsInfoResponseProto::mutable_queueuseracls(int index) {
  return queueuseracls_.Mutable(index);
}
inline ::hadoop::yarn::QueueUserACLInfoProto* GetQueueUserAclsInfoResponseProto::add_queueuseracls() {
  return queueuseracls_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::QueueUserACLInfoProto >&
GetQueueUserAclsInfoResponseProto::queueuseracls() const {
  return queueuseracls_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::QueueUserACLInfoProto >*
GetQueueUserAclsInfoResponseProto::mutable_queueuseracls() {
  return &queueuseracls_;
}

// -------------------------------------------------------------------

// StartContainerRequestProto

// optional .hadoop.yarn.ContainerLaunchContextProto container_launch_context = 1;
inline bool StartContainerRequestProto::has_container_launch_context() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void StartContainerRequestProto::set_has_container_launch_context() {
  _has_bits_[0] |= 0x00000001u;
}
inline void StartContainerRequestProto::clear_has_container_launch_context() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void StartContainerRequestProto::clear_container_launch_context() {
  if (container_launch_context_ != NULL) container_launch_context_->::hadoop::yarn::ContainerLaunchContextProto::Clear();
  clear_has_container_launch_context();
}
inline const ::hadoop::yarn::ContainerLaunchContextProto& StartContainerRequestProto::container_launch_context() const {
  return container_launch_context_ != NULL ? *container_launch_context_ : *default_instance_->container_launch_context_;
}
inline ::hadoop::yarn::ContainerLaunchContextProto* StartContainerRequestProto::mutable_container_launch_context() {
  set_has_container_launch_context();
  if (container_launch_context_ == NULL) container_launch_context_ = new ::hadoop::yarn::ContainerLaunchContextProto;
  return container_launch_context_;
}
inline ::hadoop::yarn::ContainerLaunchContextProto* StartContainerRequestProto::release_container_launch_context() {
  clear_has_container_launch_context();
  ::hadoop::yarn::ContainerLaunchContextProto* temp = container_launch_context_;
  container_launch_context_ = NULL;
  return temp;
}
inline void StartContainerRequestProto::set_allocated_container_launch_context(::hadoop::yarn::ContainerLaunchContextProto* container_launch_context) {
  delete container_launch_context_;
  container_launch_context_ = container_launch_context;
  if (container_launch_context) {
    set_has_container_launch_context();
  } else {
    clear_has_container_launch_context();
  }
}

// optional .hadoop.common.TokenProto container_token = 2;
inline bool StartContainerRequestProto::has_container_token() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void StartContainerRequestProto::set_has_container_token() {
  _has_bits_[0] |= 0x00000002u;
}
inline void StartContainerRequestProto::clear_has_container_token() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void StartContainerRequestProto::clear_container_token() {
  if (container_token_ != NULL) container_token_->::hadoop::common::TokenProto::Clear();
  clear_has_container_token();
}
inline const ::hadoop::common::TokenProto& StartContainerRequestProto::container_token() const {
  return container_token_ != NULL ? *container_token_ : *default_instance_->container_token_;
}
inline ::hadoop::common::TokenProto* StartContainerRequestProto::mutable_container_token() {
  set_has_container_token();
  if (container_token_ == NULL) container_token_ = new ::hadoop::common::TokenProto;
  return container_token_;
}
inline ::hadoop::common::TokenProto* StartContainerRequestProto::release_container_token() {
  clear_has_container_token();
  ::hadoop::common::TokenProto* temp = container_token_;
  container_token_ = NULL;
  return temp;
}
inline void StartContainerRequestProto::set_allocated_container_token(::hadoop::common::TokenProto* container_token) {
  delete container_token_;
  container_token_ = container_token;
  if (container_token) {
    set_has_container_token();
  } else {
    clear_has_container_token();
  }
}

// -------------------------------------------------------------------

// StartContainerResponseProto

// repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;
inline int StartContainerResponseProto::services_meta_data_size() const {
  return services_meta_data_.size();
}
inline void StartContainerResponseProto::clear_services_meta_data() {
  services_meta_data_.Clear();
}
inline const ::hadoop::yarn::StringBytesMapProto& StartContainerResponseProto::services_meta_data(int index) const {
  return services_meta_data_.Get(index);
}
inline ::hadoop::yarn::StringBytesMapProto* StartContainerResponseProto::mutable_services_meta_data(int index) {
  return services_meta_data_.Mutable(index);
}
inline ::hadoop::yarn::StringBytesMapProto* StartContainerResponseProto::add_services_meta_data() {
  return services_meta_data_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto >&
StartContainerResponseProto::services_meta_data() const {
  return services_meta_data_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto >*
StartContainerResponseProto::mutable_services_meta_data() {
  return &services_meta_data_;
}

// -------------------------------------------------------------------

// StopContainerRequestProto

// optional .hadoop.yarn.ContainerIdProto container_id = 1;
inline bool StopContainerRequestProto::has_container_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void StopContainerRequestProto::set_has_container_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void StopContainerRequestProto::clear_has_container_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void StopContainerRequestProto::clear_container_id() {
  if (container_id_ != NULL) container_id_->::hadoop::yarn::ContainerIdProto::Clear();
  clear_has_container_id();
}
inline const ::hadoop::yarn::ContainerIdProto& StopContainerRequestProto::container_id() const {
  return container_id_ != NULL ? *container_id_ : *default_instance_->container_id_;
}
inline ::hadoop::yarn::ContainerIdProto* StopContainerRequestProto::mutable_container_id() {
  set_has_container_id();
  if (container_id_ == NULL) container_id_ = new ::hadoop::yarn::ContainerIdProto;
  return container_id_;
}
inline ::hadoop::yarn::ContainerIdProto* StopContainerRequestProto::release_container_id() {
  clear_has_container_id();
  ::hadoop::yarn::ContainerIdProto* temp = container_id_;
  container_id_ = NULL;
  return temp;
}
inline void StopContainerRequestProto::set_allocated_container_id(::hadoop::yarn::ContainerIdProto* container_id) {
  delete container_id_;
  container_id_ = container_id;
  if (container_id) {
    set_has_container_id();
  } else {
    clear_has_container_id();
  }
}

// -------------------------------------------------------------------

// StopContainerResponseProto

// -------------------------------------------------------------------

// GetContainerStatusRequestProto

// optional .hadoop.yarn.ContainerIdProto container_id = 1;
inline bool GetContainerStatusRequestProto::has_container_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void GetContainerStatusRequestProto::set_has_container_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void GetContainerStatusRequestProto::clear_has_container_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void GetContainerStatusRequestProto::clear_container_id() {
  if (container_id_ != NULL) container_id_->::hadoop::yarn::ContainerIdProto::Clear();
  clear_has_container_id();
}
inline const ::hadoop::yarn::ContainerIdProto& GetContainerStatusRequestProto::container_id() const {
  return container_id_ != NULL ? *container_id_ : *default_instance_->container_id_;
}
inline ::hadoop::yarn::ContainerIdProto* GetContainerStatusRequestProto::mutable_container_id() {
  set_has_container_id();
  if (container_id_ == NULL) container_id_ = new ::hadoop::yarn::ContainerIdProto;
  return container_id_;
}
inline ::hadoop::yarn::ContainerIdProto* GetContainerStatusRequestProto::release_container_id() {
  clear_has_container_id();
  ::hadoop::yarn::ContainerIdProto* temp = container_id_;
  container_id_ = NULL;
  return temp;
}
inline void GetContainerStatusRequestProto::set_allocated_container_id(::hadoop::yarn::ContainerIdProto* container_id) {
  delete container_id_;
  container_id_ = container_id;
  if (container_id) {
    set_has_container_id();
  } else {
    clear_has_container_id();
  }
}

// -------------------------------------------------------------------

// GetContainerStatusResponseProto

// optional .hadoop.yarn.ContainerStatusProto status = 1;
inline bool GetContainerStatusResponseProto::has_status() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void GetContainerStatusResponseProto::set_has_status() {
  _has_bits_[0] |= 0x00000001u;
}
inline void GetContainerStatusResponseProto::clear_has_status() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void GetContainerStatusResponseProto::clear_status() {
  if (status_ != NULL) status_->::hadoop::yarn::ContainerStatusProto::Clear();
  clear_has_status();
}
inline const ::hadoop::yarn::ContainerStatusProto& GetContainerStatusResponseProto::status() const {
  return status_ != NULL ? *status_ : *default_instance_->status_;
}
inline ::hadoop::yarn::ContainerStatusProto* GetContainerStatusResponseProto::mutable_status() {
  set_has_status();
  if (status_ == NULL) status_ = new ::hadoop::yarn::ContainerStatusProto;
  return status_;
}
inline ::hadoop::yarn::ContainerStatusProto* GetContainerStatusResponseProto::release_status() {
  clear_has_status();
  ::hadoop::yarn::ContainerStatusProto* temp = status_;
  status_ = NULL;
  return temp;
}
inline void GetContainerStatusResponseProto::set_allocated_status(::hadoop::yarn::ContainerStatusProto* status) {
  delete status_;
  status_ = status;
  if (status) {
    set_has_status();
  } else {
    clear_has_status();
  }
}

// -------------------------------------------------------------------

// StartContainersRequestProto

// repeated .hadoop.yarn.StartContainerRequestProto start_container_request = 1;
inline int StartContainersRequestProto::start_container_request_size() const {
  return start_container_request_.size();
}
inline void StartContainersRequestProto::clear_start_container_request() {
  start_container_request_.Clear();
}
inline const ::hadoop::yarn::StartContainerRequestProto& StartContainersRequestProto::start_container_request(int index) const {
  return start_container_request_.Get(index);
}
inline ::hadoop::yarn::StartContainerRequestProto* StartContainersRequestProto::mutable_start_container_request(int index) {
  return start_container_request_.Mutable(index);
}
inline ::hadoop::yarn::StartContainerRequestProto* StartContainersRequestProto::add_start_container_request() {
  return start_container_request_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StartContainerRequestProto >&
StartContainersRequestProto::start_container_request() const {
  return start_container_request_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StartContainerRequestProto >*
StartContainersRequestProto::mutable_start_container_request() {
  return &start_container_request_;
}

// -------------------------------------------------------------------

// ContainerExceptionMapProto

// optional .hadoop.yarn.ContainerIdProto container_id = 1;
inline bool ContainerExceptionMapProto::has_container_id() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ContainerExceptionMapProto::set_has_container_id() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ContainerExceptionMapProto::clear_has_container_id() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ContainerExceptionMapProto::clear_container_id() {
  if (container_id_ != NULL) container_id_->::hadoop::yarn::ContainerIdProto::Clear();
  clear_has_container_id();
}
inline const ::hadoop::yarn::ContainerIdProto& ContainerExceptionMapProto::container_id() const {
  return container_id_ != NULL ? *container_id_ : *default_instance_->container_id_;
}
inline ::hadoop::yarn::ContainerIdProto* ContainerExceptionMapProto::mutable_container_id() {
  set_has_container_id();
  if (container_id_ == NULL) container_id_ = new ::hadoop::yarn::ContainerIdProto;
  return container_id_;
}
inline ::hadoop::yarn::ContainerIdProto* ContainerExceptionMapProto::release_container_id() {
  clear_has_container_id();
  ::hadoop::yarn::ContainerIdProto* temp = container_id_;
  container_id_ = NULL;
  return temp;
}
inline void ContainerExceptionMapProto::set_allocated_container_id(::hadoop::yarn::ContainerIdProto* container_id) {
  delete container_id_;
  container_id_ = container_id;
  if (container_id) {
    set_has_container_id();
  } else {
    clear_has_container_id();
  }
}

// optional .hadoop.yarn.SerializedExceptionProto exception = 2;
inline bool ContainerExceptionMapProto::has_exception() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ContainerExceptionMapProto::set_has_exception() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ContainerExceptionMapProto::clear_has_exception() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ContainerExceptionMapProto::clear_exception() {
  if (exception_ != NULL) exception_->::hadoop::yarn::SerializedExceptionProto::Clear();
  clear_has_exception();
}
inline const ::hadoop::yarn::SerializedExceptionProto& ContainerExceptionMapProto::exception() const {
  return exception_ != NULL ? *exception_ : *default_instance_->exception_;
}
inline ::hadoop::yarn::SerializedExceptionProto* ContainerExceptionMapProto::mutable_exception() {
  set_has_exception();
  if (exception_ == NULL) exception_ = new ::hadoop::yarn::SerializedExceptionProto;
  return exception_;
}
inline ::hadoop::yarn::SerializedExceptionProto* ContainerExceptionMapProto::release_exception() {
  clear_has_exception();
  ::hadoop::yarn::SerializedExceptionProto* temp = exception_;
  exception_ = NULL;
  return temp;
}
inline void ContainerExceptionMapProto::set_allocated_exception(::hadoop::yarn::SerializedExceptionProto* exception) {
  delete exception_;
  exception_ = exception;
  if (exception) {
    set_has_exception();
  } else {
    clear_has_exception();
  }
}

// -------------------------------------------------------------------

// StartContainersResponseProto

// repeated .hadoop.yarn.StringBytesMapProto services_meta_data = 1;
inline int StartContainersResponseProto::services_meta_data_size() const {
  return services_meta_data_.size();
}
inline void StartContainersResponseProto::clear_services_meta_data() {
  services_meta_data_.Clear();
}
inline const ::hadoop::yarn::StringBytesMapProto& StartContainersResponseProto::services_meta_data(int index) const {
  return services_meta_data_.Get(index);
}
inline ::hadoop::yarn::StringBytesMapProto* StartContainersResponseProto::mutable_services_meta_data(int index) {
  return services_meta_data_.Mutable(index);
}
inline ::hadoop::yarn::StringBytesMapProto* StartContainersResponseProto::add_services_meta_data() {
  return services_meta_data_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto >&
StartContainersResponseProto::services_meta_data() const {
  return services_meta_data_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::StringBytesMapProto >*
StartContainersResponseProto::mutable_services_meta_data() {
  return &services_meta_data_;
}

// repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 2;
inline int StartContainersResponseProto::succeeded_requests_size() const {
  return succeeded_requests_.size();
}
inline void StartContainersResponseProto::clear_succeeded_requests() {
  succeeded_requests_.Clear();
}
inline const ::hadoop::yarn::ContainerIdProto& StartContainersResponseProto::succeeded_requests(int index) const {
  return succeeded_requests_.Get(index);
}
inline ::hadoop::yarn::ContainerIdProto* StartContainersResponseProto::mutable_succeeded_requests(int index) {
  return succeeded_requests_.Mutable(index);
}
inline ::hadoop::yarn::ContainerIdProto* StartContainersResponseProto::add_succeeded_requests() {
  return succeeded_requests_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >&
StartContainersResponseProto::succeeded_requests() const {
  return succeeded_requests_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >*
StartContainersResponseProto::mutable_succeeded_requests() {
  return &succeeded_requests_;
}

// repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 3;
inline int StartContainersResponseProto::failed_requests_size() const {
  return failed_requests_.size();
}
inline void StartContainersResponseProto::clear_failed_requests() {
  failed_requests_.Clear();
}
inline const ::hadoop::yarn::ContainerExceptionMapProto& StartContainersResponseProto::failed_requests(int index) const {
  return failed_requests_.Get(index);
}
inline ::hadoop::yarn::ContainerExceptionMapProto* StartContainersResponseProto::mutable_failed_requests(int index) {
  return failed_requests_.Mutable(index);
}
inline ::hadoop::yarn::ContainerExceptionMapProto* StartContainersResponseProto::add_failed_requests() {
  return failed_requests_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto >&
StartContainersResponseProto::failed_requests() const {
  return failed_requests_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto >*
StartContainersResponseProto::mutable_failed_requests() {
  return &failed_requests_;
}

// -------------------------------------------------------------------

// StopContainersRequestProto

// repeated .hadoop.yarn.ContainerIdProto container_id = 1;
inline int StopContainersRequestProto::container_id_size() const {
  return container_id_.size();
}
inline void StopContainersRequestProto::clear_container_id() {
  container_id_.Clear();
}
inline const ::hadoop::yarn::ContainerIdProto& StopContainersRequestProto::container_id(int index) const {
  return container_id_.Get(index);
}
inline ::hadoop::yarn::ContainerIdProto* StopContainersRequestProto::mutable_container_id(int index) {
  return container_id_.Mutable(index);
}
inline ::hadoop::yarn::ContainerIdProto* StopContainersRequestProto::add_container_id() {
  return container_id_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >&
StopContainersRequestProto::container_id() const {
  return container_id_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >*
StopContainersRequestProto::mutable_container_id() {
  return &container_id_;
}

// -------------------------------------------------------------------

// StopContainersResponseProto

// repeated .hadoop.yarn.ContainerIdProto succeeded_requests = 1;
inline int StopContainersResponseProto::succeeded_requests_size() const {
  return succeeded_requests_.size();
}
inline void StopContainersResponseProto::clear_succeeded_requests() {
  succeeded_requests_.Clear();
}
inline const ::hadoop::yarn::ContainerIdProto& StopContainersResponseProto::succeeded_requests(int index) const {
  return succeeded_requests_.Get(index);
}
inline ::hadoop::yarn::ContainerIdProto* StopContainersResponseProto::mutable_succeeded_requests(int index) {
  return succeeded_requests_.Mutable(index);
}
inline ::hadoop::yarn::ContainerIdProto* StopContainersResponseProto::add_succeeded_requests() {
  return succeeded_requests_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >&
StopContainersResponseProto::succeeded_requests() const {
  return succeeded_requests_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >*
StopContainersResponseProto::mutable_succeeded_requests() {
  return &succeeded_requests_;
}

// repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;
inline int StopContainersResponseProto::failed_requests_size() const {
  return failed_requests_.size();
}
inline void StopContainersResponseProto::clear_failed_requests() {
  failed_requests_.Clear();
}
inline const ::hadoop::yarn::ContainerExceptionMapProto& StopContainersResponseProto::failed_requests(int index) const {
  return failed_requests_.Get(index);
}
inline ::hadoop::yarn::ContainerExceptionMapProto* StopContainersResponseProto::mutable_failed_requests(int index) {
  return failed_requests_.Mutable(index);
}
inline ::hadoop::yarn::ContainerExceptionMapProto* StopContainersResponseProto::add_failed_requests() {
  return failed_requests_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto >&
StopContainersResponseProto::failed_requests() const {
  return failed_requests_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto >*
StopContainersResponseProto::mutable_failed_requests() {
  return &failed_requests_;
}

// -------------------------------------------------------------------

// GetContainerStatusesRequestProto

// repeated .hadoop.yarn.ContainerIdProto container_id = 1;
inline int GetContainerStatusesRequestProto::container_id_size() const {
  return container_id_.size();
}
inline void GetContainerStatusesRequestProto::clear_container_id() {
  container_id_.Clear();
}
inline const ::hadoop::yarn::ContainerIdProto& GetContainerStatusesRequestProto::container_id(int index) const {
  return container_id_.Get(index);
}
inline ::hadoop::yarn::ContainerIdProto* GetContainerStatusesRequestProto::mutable_container_id(int index) {
  return container_id_.Mutable(index);
}
inline ::hadoop::yarn::ContainerIdProto* GetContainerStatusesRequestProto::add_container_id() {
  return container_id_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >&
GetContainerStatusesRequestProto::container_id() const {
  return container_id_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerIdProto >*
GetContainerStatusesRequestProto::mutable_container_id() {
  return &container_id_;
}

// -------------------------------------------------------------------

// GetContainerStatusesResponseProto

// repeated .hadoop.yarn.ContainerStatusProto status = 1;
inline int GetContainerStatusesResponseProto::status_size() const {
  return status_.size();
}
inline void GetContainerStatusesResponseProto::clear_status() {
  status_.Clear();
}
inline const ::hadoop::yarn::ContainerStatusProto& GetContainerStatusesResponseProto::status(int index) const {
  return status_.Get(index);
}
inline ::hadoop::yarn::ContainerStatusProto* GetContainerStatusesResponseProto::mutable_status(int index) {
  return status_.Mutable(index);
}
inline ::hadoop::yarn::ContainerStatusProto* GetContainerStatusesResponseProto::add_status() {
  return status_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerStatusProto >&
GetContainerStatusesResponseProto::status() const {
  return status_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerStatusProto >*
GetContainerStatusesResponseProto::mutable_status() {
  return &status_;
}

// repeated .hadoop.yarn.ContainerExceptionMapProto failed_requests = 2;
inline int GetContainerStatusesResponseProto::failed_requests_size() const {
  return failed_requests_.size();
}
inline void GetContainerStatusesResponseProto::clear_failed_requests() {
  failed_requests_.Clear();
}
inline const ::hadoop::yarn::ContainerExceptionMapProto& GetContainerStatusesResponseProto::failed_requests(int index) const {
  return failed_requests_.Get(index);
}
inline ::hadoop::yarn::ContainerExceptionMapProto* GetContainerStatusesResponseProto::mutable_failed_requests(int index) {
  return failed_requests_.Mutable(index);
}
inline ::hadoop::yarn::ContainerExceptionMapProto* GetContainerStatusesResponseProto::add_failed_requests() {
  return failed_requests_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto >&
GetContainerStatusesResponseProto::failed_requests() const {
  return failed_requests_;
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::yarn::ContainerExceptionMapProto >*
GetContainerStatusesResponseProto::mutable_failed_requests() {
  return &failed_requests_;
}


// @@protoc_insertion_point(namespace_scope)

}  // namespace yarn
}  // namespace hadoop

#ifndef SWIG
namespace google {
namespace protobuf {


}  // namespace google
}  // namespace protobuf
#endif  // SWIG

// @@protoc_insertion_point(global_scope)

#endif  // PROTOBUF_yarn_5fservice_5fprotos_2eproto__INCLUDED
